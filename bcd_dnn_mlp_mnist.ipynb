{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Block Coordinate Descent (BCD) Algorithm for Training DNNs (3-layer MLP) \n",
    "(MNIST dataset)\n",
    "5 runs, seed = 10, 20, 30, 40, 50; \n",
    "validation accuracies: 0.9565, 0.9559, 0.9568, 0.9546, 0.9537\n",
    "\"\"\"\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# print(\"PyTorch Version: \",torch.__version__)\n",
    "# print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\") # Uncomment this to run on CPU\n",
    "# device = torch.device(\"cuda:0\") \n",
    "\n",
    "ts = transforms.Compose([transforms.ToTensor(), # Convert to tensor and scale to [0, 1]\n",
    "                             transforms.Normalize((0,), (1,))])\n",
    "mnist_trainset = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=ts)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, \n",
    "                        transform=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate train set\n",
    "x_d1 = mnist_trainset[0][0].size()[1]\n",
    "x_d2 = mnist_trainset[0][0].size()[2]\n",
    "N = x_d3 = len(mnist_trainset)\n",
    "K = 10\n",
    "x_train = torch.empty((N,x_d1*x_d2), device=device)\n",
    "y_train = torch.empty(N, dtype=torch.long)\n",
    "for i in range(N): \n",
    "     x_train[i,:] = torch.reshape(mnist_trainset[i][0], (1,x_d1*x_d2))\n",
    "     y_train[i] = mnist_trainset[i][1]\n",
    "x_train = torch.t(x_train)\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train,(N,1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate test set\n",
    "x_d1_test = mnist_testset[0][0].size()[1]\n",
    "x_d2_test = mnist_testset[0][0].size()[2]\n",
    "N_test = x_d3_test = len(mnist_testset)\n",
    "x_test = torch.empty((10000,784), device=device)\n",
    "y_test = torch.empty(10000, dtype=torch.long)\n",
    "for i in range(10000): \n",
    "     x_test[i,:] = torch.reshape(mnist_testset[i][0], (1,28*28))\n",
    "     y_test[i] = mnist_testset[i][1]\n",
    "x_test = torch.t(x_test)\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test,(N_test,1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main Algorithm (Jinshan's Algorithm)\n",
    "# Initialization of parameters \n",
    "torch.manual_seed(10)\n",
    "d0 = x_d1*x_d2\n",
    "d1 = d2 = d3 = 2048\n",
    "d4 = K # Layers: input + 3 hidden + output\n",
    "W1 = 0.01*torch.randn(d1, d0, device=device)\n",
    "b1 = 0.1*torch.ones(d1, 1, device=device)\n",
    "W2 = 0.01*torch.randn(d2, d1, device=device)\n",
    "b2 = 0.1*torch.ones(d2, 1, device=device)\n",
    "W3 = 0.01*torch.randn(d3, d2, device=device)\n",
    "b3 = 0.1*torch.ones(d3, 1, device=device)\n",
    "W4 = 0.01*torch.randn(d4, d3, device=device)\n",
    "b4 = 0.1*torch.ones(d4, 1, device=device)\n",
    "\n",
    "U1 = torch.addmm(b1.repeat(1, N), W1, x_train)\n",
    "V1 = nn.ReLU()(U1)\n",
    "U2 = torch.addmm(b2.repeat(1, N), W2, V1)\n",
    "V2 = nn.ReLU()(U2)\n",
    "U3 = torch.addmm(b3.repeat(1, N), W3, V2)\n",
    "V3 = nn.ReLU()(U3) \n",
    "U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "V4 = U4\n",
    "\n",
    "gamma = 1\n",
    "gamma1 = gamma2 = gamma3 = gamma4 = gamma\n",
    "\n",
    "rho = gamma\n",
    "rho1 = rho2 = rho3 = rho4 = rho\n",
    "\n",
    "\n",
    "alpha = 1\n",
    "alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 \\\n",
    "= alpha8 = alpha9 = alpha10 = alpha\n",
    "\n",
    "niter = 10\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "layer1 = np.empty(niter)\n",
    "layer2 = np.empty(niter)\n",
    "layer3 = np.empty(niter)\n",
    "layer4 = np.empty(niter)\n",
    "layer11 = np.empty(niter)\n",
    "layer21 = np.empty(niter)\n",
    "layer31 = np.empty(niter)\n",
    "layer41 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV_js(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W))+gamma*I), rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2))+gamma*U1)\n",
    "    return Vstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWb_js(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W+rho*torch.mm(U-b.repeat(1,col_U),torch.t(V)),torch.inverse(alpha*I+rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = (alpha*b+rho*torch.sum(U-torch.mm(W,V), dim=1).reshape(b.size()))/(rho*N+alpha)\n",
    "    return Wstar, bstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , squared loss: 12377.8818359375 , total loss: 12397.269643247128 , training accuracy: 0.68725 , validation accuracy: 0.6907\n",
      "time: 64.73594999313354\n",
      "epoch: 1 , squared loss: 6966.5390625 , total loss: 6989.15206989646 , training accuracy: 0.9283666666666667 , validation accuracy: 0.9255\n",
      "time: 63.01446199417114\n",
      "epoch: 2 , squared loss: 4231.8671875 , total loss: 4245.285740941763 , training accuracy: 0.9467333333333333 , validation accuracy: 0.942\n",
      "time: 64.86120963096619\n",
      "epoch: 3 , squared loss: 2620.913818359375 , total loss: 2635.532652273774 , training accuracy: 0.95335 , validation accuracy: 0.9474\n",
      "time: 65.2726616859436\n",
      "epoch: 4 , squared loss: 1632.1497802734375 , total loss: 1650.6349717900157 , training accuracy: 0.9555666666666667 , validation accuracy: 0.95\n",
      "time: 65.11454772949219\n",
      "epoch: 5 , squared loss: 1016.0925903320312 , total loss: 1031.8026821911335 , training accuracy: 0.9588833333333333 , validation accuracy: 0.9521\n",
      "time: 67.66342544555664\n",
      "epoch: 6 , squared loss: 632.8558959960938 , total loss: 650.3930169157684 , training accuracy: 0.9607166666666667 , validation accuracy: 0.9536\n",
      "time: 66.51197743415833\n",
      "epoch: 7 , squared loss: 394.5160217285156 , total loss: 410.8723345445469 , training accuracy: 0.9621166666666666 , validation accuracy: 0.954\n",
      "time: 66.319331407547\n",
      "epoch: 8 , squared loss: 245.66714477539062 , total loss: 261.2031038189307 , training accuracy: 0.9624666666666667 , validation accuracy: 0.953\n",
      "time: 64.1505651473999\n",
      "epoch: 9 , squared loss: 153.0520477294922 , total loss: 168.54076227452606 , training accuracy: 0.9632166666666667 , validation accuracy: 0.9543\n",
      "time: 69.27974796295166\n"
     ]
    }
   ],
   "source": [
    "# Iterations\n",
    "for k in range(niter):\n",
    "    start = time.time()\n",
    "     # record previous W1, W2, W3, W4, b1, b2, b3, b4\n",
    "    W10 = W1\n",
    "    W20 = W2\n",
    "    W30 = W3\n",
    "    W40 = W4\n",
    "    b10 = b1\n",
    "    b20 = b2\n",
    "    b30 = b3\n",
    "    b40 = b4\n",
    "\n",
    "    # update V4\n",
    "    V4 = (y_one_hot + gamma4*U4 + alpha1*V4)/(1 + gamma4 + alpha1)\n",
    "    \n",
    "    # update U4 \n",
    "    U4 = (gamma4*V4 + rho4*(torch.mm(W4,V3) + b4.repeat(1,N)))/(gamma4 + rho4)\n",
    "\n",
    "    # update W4 and b4\n",
    "    W4, b4 = updateWb_js(U4,V3,W4,b4,alpha2,rho4)\n",
    "    \n",
    "    # update V3\n",
    "    V3 = updateV_js(U3,U4,W4,b4,rho4,gamma3)\n",
    "    \n",
    "    # update U3\n",
    "    U3 = relu_prox(V3,(rho3*torch.addmm(b3.repeat(1,N), W3, V2) + alpha3*U3)/(rho3 + alpha3),(rho3 + alpha3)/gamma3,d3,N)\n",
    "    \n",
    "    # update W3 and b3\n",
    "    W3, b3 = updateWb_js(U3,V2,W3,b3,alpha4,rho3)\n",
    "    \n",
    "    # update V2\n",
    "    V2 = updateV_js(U2,U3,W3,b3,rho3,gamma2)\n",
    "    \n",
    "    # update U2\n",
    "    U2 = relu_prox(V2,(rho2*torch.addmm(b2.repeat(1,N), W2, V1) + alpha5*U2)/(rho2 + alpha5),(rho2 + alpha5)/gamma2,d2,N)\n",
    "    \n",
    "    # update W2 and b2\n",
    "    W2, b2 = updateWb_js(U2,V1,W2,b2,alpha6,rho2)\n",
    "\n",
    "    # update V1\n",
    "    V1 = updateV_js(U1,U2,W2,b2,rho2,gamma1)\n",
    "    \n",
    "    # update U1\n",
    "    U1 = relu_prox(V1,(rho1*torch.addmm(b1.repeat(1,N), W1, x_train) + alpha7*U1)/(rho1 + alpha7),(rho1 + alpha7)/gamma1,d1,N)\n",
    "\n",
    "    # update W1 and b1\n",
    "    W1, b1 = updateWb_js(U1,x_train,W1,b1,alpha8,rho1)\n",
    "\n",
    "    a1_train = nn.ReLU()(torch.addmm(b1.repeat(1, 60000), W1, x_train))\n",
    "    a2_train = nn.ReLU()(torch.addmm(b2.repeat(1, 60000), W2, a1_train))\n",
    "    a3_train = nn.ReLU()(torch.addmm(b3.repeat(1, 60000), W3, a2_train))\n",
    "    pred = torch.argmax(torch.addmm(b4.repeat(1, 60000), W4, a3_train), dim=0)\n",
    "\n",
    "    a1_test = nn.ReLU()(torch.addmm(b1.repeat(1, 10000), W1, x_test))\n",
    "    a2_test = nn.ReLU()(torch.addmm(b2.repeat(1, 10000), W2, a1_test))\n",
    "    a3_test = nn.ReLU()(torch.addmm(b3.repeat(1, 10000), W3, a2_test))\n",
    "    pred_test = torch.argmax(torch.addmm(b4.repeat(1, 10000), W4, a3_test), dim=0)\n",
    "    \n",
    "    loss1[k] = gamma4/2*torch.pow(torch.dist(V4,y_one_hot,2),2).cpu().numpy()\n",
    "    loss2[k] = loss1[k] + rho1/2*torch.pow(torch.dist(torch.addmm(b1.repeat(1,N), W1, x_train),U1,2),2).cpu().numpy() \\\n",
    "    +rho2/2*torch.pow(torch.dist(torch.addmm(b2.repeat(1,N), W2, V1),U2,2),2).cpu().numpy() \\\n",
    "    +rho3/2*torch.pow(torch.dist(torch.addmm(b3.repeat(1,N), W3, V2),U3,2),2).cpu().numpy() \\\n",
    "    +rho4/2*torch.pow(torch.dist(torch.addmm(b4.repeat(1,N), W4, V3),U4,2),2).cpu().numpy()\n",
    "    \n",
    "    correct_train = pred == y_train\n",
    "    accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "    correct_test = pred_test == y_test\n",
    "    accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "    stop = time.time()\n",
    "    duration = stop-start\n",
    "    time1[k] = duration\n",
    "    print('epoch:', k, ',', 'squared loss:', loss1[k], ',', 'total loss:', loss2[k], ',', 'training accuracy:', accuracy_train[k], ',', 'validation accuracy:', accuracy_test[k])\n",
    "    print('time:', time1[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
