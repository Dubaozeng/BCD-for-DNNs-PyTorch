{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinplementation of Block Coordinate Descent (BCD) Algorithm for Training DNNs (10-layer MLP) for MNIST in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 0.4.1.post2\n",
      "Torchvision Version: 0.2.1\n",
      "GPU is available? True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5 runs, seed = 5, 10, 15, 8, 19; \n",
    "validation accuracies: 0.8721, 0.8695, 0.8564, 0.8713, 0.8617\n",
    "\"\"\"\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n",
    "print(\"GPU is available?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\") # Uncomment this to run on CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Uncomment this to run on GPU\n",
    "\n",
    "# Convert to tensor and scale to [0, 1]\n",
    "ts = transforms.Compose([transforms.ToTensor(), \n",
    "                             transforms.Normalize((0,), (1,))])\n",
    "mnist_trainset = datasets.MNIST('../data', train=True, download=True, transform=ts)\n",
    "mnist_testset = datasets.MNIST(root='../data', train=False, download=True, transform=ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate train set\n",
    "x_d1 = mnist_trainset[0][0].size()[1]\n",
    "x_d2 = mnist_trainset[0][0].size()[2]\n",
    "N = x_d3 = len(mnist_trainset)\n",
    "K = 10\n",
    "x_train = torch.empty((N,x_d1*x_d2), device=device)\n",
    "y_train = torch.empty(N, dtype=torch.long)\n",
    "for i in range(N): \n",
    "     x_train[i,:] = torch.reshape(mnist_trainset[i][0], (1, x_d1*x_d2))\n",
    "     y_train[i] = mnist_trainset[i][1]\n",
    "x_train = torch.t(x_train)\n",
    "y_one_hot = torch.zeros(N, K).scatter_(1, torch.reshape(y_train, (N, 1)), 1)\n",
    "y_one_hot = torch.t(y_one_hot).to(device=device)\n",
    "y_train = y_train.to(device=device)\n",
    "\n",
    "# Manipulate test set\n",
    "N_test = x_d3_test = len(mnist_testset)\n",
    "x_test = torch.empty((N_test,x_d1*x_d2), device=device)\n",
    "y_test = torch.empty(N_test, dtype=torch.long)\n",
    "for i in range(N_test): \n",
    "     x_test[i,:] = torch.reshape(mnist_testset[i][0], (1, x_d1*x_d2))\n",
    "     y_test[i] = mnist_testset[i][1]\n",
    "x_test = torch.t(x_test)\n",
    "y_test_one_hot = torch.zeros(N_test, K).scatter_(1, torch.reshape(y_test, (N_test, 1)), 1)\n",
    "y_test_one_hot = torch.t(y_test_one_hot).to(device=device)\n",
    "y_test = y_test.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main algorithm (Jinshan's Algorithm in Zeng et al (2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameter initialization and forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of parameters\n",
    "torch.manual_seed(5)\n",
    "def initialize(dim_in, dim_out):\n",
    "    W = 0.01*torch.randn(dim_out, dim_in, device=device)\n",
    "    b = 0.1*torch.ones(dim_out, 1, device=device)\n",
    "    return W, b\n",
    "\n",
    "# Forward pass\n",
    "def feed_forward(weight, bias, activation, dim = N):\n",
    "    U = torch.addmm(bias.repeat(1, dim), weight, activation)\n",
    "    V = nn.ReLU()(U)\n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for updating blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateV_js(U1,U2,W,b,rho,gamma): \n",
    "    _, d = W.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    U1 = nn.ReLU()(U1)\n",
    "    _, col_U2 = U2.size()\n",
    "    Vstar = torch.mm(torch.inverse(rho*(torch.mm(torch.t(W),W)) + gamma*I), \\\n",
    "                     rho*torch.mm(torch.t(W),U2-b.repeat(1,col_U2)) + gamma*U1)\n",
    "    return Vstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWb_js(U, V, W, b, alpha, rho): \n",
    "    d,N = V.size()\n",
    "    I = torch.eye(d, device=device)\n",
    "    _, col_U = U.size()\n",
    "    Wstar = torch.mm(alpha*W + rho*torch.mm(U - b.repeat(1,col_U),torch.t(V)),\\\n",
    "                     torch.inverse(alpha*I + rho*(torch.mm(V,torch.t(V)))))\n",
    "    bstar = (alpha*b+rho*torch.sum(U-torch.mm(W,V), dim=1).reshape(b.size()))/(rho*N + alpha)\n",
    "    return Wstar, bstar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the proximal operator of the ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_prox(a, b, gamma, d, N):\n",
    "    val = torch.empty(d,N, device=device)\n",
    "    x = (a+gamma*b)/(1+gamma)\n",
    "    y = torch.min(b,torch.zeros(d,N, device=device))\n",
    "\n",
    "    val = torch.where(a+gamma*b < 0, y, torch.zeros(d,N, device=device))\n",
    "    val = torch.where(((a+gamma*b >= 0) & (b >=0)) | ((a*(gamma-np.sqrt(gamma*(gamma+1))) <= gamma*b) & (b < 0)), x, val)\n",
    "    val = torch.where((-a <= gamma*b) & (gamma*b <= a*(gamma-np.sqrt(gamma*(gamma+1)))), b, val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1\n",
    "# gamma1 = gamma2 = gamma3 = gamma4 = gamma5 = gamma6 \\\n",
    "# = gamma7 = gamma8 = gamma9 = gamma10 = gamma11 = gamma\n",
    "\n",
    "rho = 1\n",
    "# rho1 = rho2 = rho3 = rho4 = rho5 = rho6 = rho7 = rho8 \n",
    "# = rho9 = rho10 = rho11 = rho \n",
    "\n",
    "\n",
    "alpha = 1\n",
    "# alpha1 = alpha2 = alpha3 = alpha4 = alpha5 = alpha6 = alpha7 \\\n",
    "# = alpha8 = alpha9 = alpha10 = alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define block update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_update(Wn, bn, Wn_1, bn_1, Vn, Un, Vn_1, Un_1, Vn_2, dn_1, alpha = alpha, gamma = gamma, rho = rho, dim = N):\n",
    "    # update W(n) and b(n)\n",
    "    Wn, bn = updateWb_js(Un, Vn_1, Wn, bn, alpha, rho)\n",
    "    # update V(n-1)\n",
    "    Vn_1 = updateV_js(Un_1, Un, Wn, bn, rho, gamma)\n",
    "    # update U(n-1)\n",
    "    Un_1 = relu_prox(Vn_1, (rho*torch.addmm(bn_1.repeat(1,dim), Wn_1, Vn_2) + \\\n",
    "                            alpha*Un_1)/(rho + alpha), (rho + alpha)/gamma, dn_1, dim)\n",
    "    return Wn, bn, Vn_1, Un_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss computation of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(weight, bias, activation, preactivation, rho = rho):\n",
    "    loss = rho/2*torch.pow(torch.dist(torch.addmm(bias.repeat(1,N), \\\n",
    "                                                  weight, activation), preactivation, 2), 2).cpu().numpy()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers: input + 3 hidden + output\n",
    "d0 = x_d1*x_d2\n",
    "d1 = d2 = d3 = d4 = d5 = d6 \\\n",
    "= d7 = d8 = d9 = d10 = 600\n",
    "d11 = K \n",
    "\n",
    "\n",
    "W1, b1 = initialize(d0, d1)\n",
    "W2, b2 = initialize(d1, d2)\n",
    "W3, b3 = initialize(d2, d3)\n",
    "W4, b4 = initialize(d3, d4)\n",
    "W5, b5 = initialize(d4, d5)\n",
    "W6, b6 = initialize(d5, d6)\n",
    "W7, b7 = initialize(d6, d7)\n",
    "W8, b8 = initialize(d7, d8)\n",
    "W9, b9 = initialize(d8, d9)\n",
    "W10, b10 = initialize(d9, d10)\n",
    "W11, b11 = initialize(d10, d11)\n",
    "\n",
    "\n",
    "U1, V1 = feed_forward(W1, b1, x_train)\n",
    "U2, V2 = feed_forward(W2, b2, V1)\n",
    "U3, V3 = feed_forward(W3, b3, V2)\n",
    "# U4 = torch.addmm(b4.repeat(1, N), W4, V3)\n",
    "# V4 = U4\n",
    "U4, V4 = feed_forward(W4, b4, V3)\n",
    "U5, V5 = feed_forward(W5, b5, V4)\n",
    "U6, V6 = feed_forward(W6, b6, V5)\n",
    "U7, V7 = feed_forward(W7, b7, V6)\n",
    "U8, V8 = feed_forward(W8, b8, V7)\n",
    "U9, V9 = feed_forward(W9, b9, V8)\n",
    "U10, V10 = feed_forward(W10, b10, V9)\n",
    "U11 = torch.addmm(b11.repeat(1, N), W11, V10)\n",
    "V11 = U11\n",
    "\n",
    "niter = 300\n",
    "loss1 = np.empty(niter)\n",
    "loss2 = np.empty(niter)\n",
    "# layer1 = np.empty(niter)\n",
    "# layer2 = np.empty(niter)\n",
    "# layer3 = np.empty(niter)\n",
    "# layer4 = np.empty(niter)\n",
    "# layer11 = np.empty(niter)\n",
    "# layer21 = np.empty(niter)\n",
    "# layer31 = np.empty(niter)\n",
    "# layer41 = np.empty(niter)\n",
    "accuracy_train = np.empty(niter)\n",
    "accuracy_test = np.empty(niter)\n",
    "time1 = np.empty(niter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1 / 300 \n",
      " - time (s): 1.983821153640747 - sq_loss: 15380.4462890625 - tot_loss: 15754.53091503866 - acc: 0.10218333333333333 - val_acc: 0.101\n",
      "Epoch 2 / 300 \n",
      " - time (s): 1.7298214435577393 - sq_loss: 9639.4794921875 - tot_loss: 9645.937349281274 - acc: 0.10218333333333333 - val_acc: 0.101\n",
      "Epoch 3 / 300 \n",
      " - time (s): 1.7122306823730469 - sq_loss: 6691.13232421875 - tot_loss: 6697.861228738911 - acc: 0.10218333333333333 - val_acc: 0.101\n",
      "Epoch 4 / 300 \n",
      " - time (s): 1.7037200927734375 - sq_loss: 4570.76171875 - tot_loss: 4575.9033736772835 - acc: 0.10218333333333333 - val_acc: 0.101\n",
      "Epoch 5 / 300 \n",
      " - time (s): 1.8546056747436523 - sq_loss: 3100.06982421875 - tot_loss: 3103.6585286417976 - acc: 0.10218333333333333 - val_acc: 0.101\n",
      "Epoch 6 / 300 \n",
      " - time (s): 1.7666988372802734 - sq_loss: 2096.298583984375 - tot_loss: 2099.403638130054 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 7 / 300 \n",
      " - time (s): 1.7388525009155273 - sq_loss: 1415.8204345703125 - tot_loss: 1418.617987865582 - acc: 0.10695 - val_acc: 0.1048\n",
      "Epoch 8 / 300 \n",
      " - time (s): 1.7845182418823242 - sq_loss: 955.7447509765625 - tot_loss: 958.343130341731 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 9 / 300 \n",
      " - time (s): 1.8506767749786377 - sq_loss: 645.0108032226562 - tot_loss: 647.3084492059425 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 10 / 300 \n",
      " - time (s): 1.8458878993988037 - sq_loss: 435.2414855957031 - tot_loss: 437.58705807849765 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 11 / 300 \n",
      " - time (s): 1.7229859828948975 - sq_loss: 293.6636657714844 - tot_loss: 296.19003766868263 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 12 / 300 \n",
      " - time (s): 1.7450146675109863 - sq_loss: 198.12916564941406 - tot_loss: 200.19579904619604 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 13 / 300 \n",
      " - time (s): 1.7759125232696533 - sq_loss: 133.67242431640625 - tot_loss: 135.53195757581852 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 14 / 300 \n",
      " - time (s): 1.8738629817962646 - sq_loss: 90.1859359741211 - tot_loss: 91.82466542068869 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 15 / 300 \n",
      " - time (s): 1.8959369659423828 - sq_loss: 60.85000228881836 - tot_loss: 62.343604994239286 - acc: 0.11445 - val_acc: 0.1156\n",
      "Epoch 16 / 300 \n",
      " - time (s): 2.007240056991577 - sq_loss: 41.05943298339844 - tot_loss: 42.51539904589299 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 17 / 300 \n",
      " - time (s): 1.9263927936553955 - sq_loss: 27.707868576049805 - tot_loss: 29.199073802912608 - acc: 0.09863333333333334 - val_acc: 0.0958\n",
      "Epoch 18 / 300 \n",
      " - time (s): 1.869755744934082 - sq_loss: 18.699954986572266 - tot_loss: 20.616045546310488 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 19 / 300 \n",
      " - time (s): 1.8384382724761963 - sq_loss: 12.623340606689453 - tot_loss: 14.092670361336786 - acc: 0.09863333333333334 - val_acc: 0.0958\n",
      "Epoch 20 / 300 \n",
      " - time (s): 1.8281362056732178 - sq_loss: 8.522350311279297 - tot_loss: 9.91574078213307 - acc: 0.1899 - val_acc: 0.192\n",
      "Epoch 21 / 300 \n",
      " - time (s): 1.8540236949920654 - sq_loss: 5.754887104034424 - tot_loss: 7.104143626900623 - acc: 0.0993 - val_acc: 0.1032\n",
      "Epoch 22 / 300 \n",
      " - time (s): 1.8654723167419434 - sq_loss: 3.8871138095855713 - tot_loss: 5.1513136749272235 - acc: 0.12128333333333334 - val_acc: 0.1228\n",
      "Epoch 23 / 300 \n",
      " - time (s): 1.893798828125 - sq_loss: 2.6260933876037598 - tot_loss: 4.09086147895141 - acc: 0.14913333333333334 - val_acc: 0.1494\n",
      "Epoch 24 / 300 \n",
      " - time (s): 1.85451340675354 - sq_loss: 1.7746957540512085 - tot_loss: 3.081395257569966 - acc: 0.13931666666666667 - val_acc: 0.1451\n",
      "Epoch 25 / 300 \n",
      " - time (s): 1.7915043830871582 - sq_loss: 1.1998966932296753 - tot_loss: 2.5212381800083676 - acc: 0.10081666666666667 - val_acc: 0.0979\n",
      "Epoch 26 / 300 \n",
      " - time (s): 1.8041517734527588 - sq_loss: 0.8115392923355103 - tot_loss: 1.991225131234387 - acc: 0.11236666666666667 - val_acc: 0.1135\n",
      "Epoch 27 / 300 \n",
      " - time (s): 1.9595637321472168 - sq_loss: 0.5491551160812378 - tot_loss: 1.6472664138273103 - acc: 0.10293333333333334 - val_acc: 0.1023\n",
      "Epoch 28 / 300 \n",
      " - time (s): 1.733574628829956 - sq_loss: 0.371830016374588 - tot_loss: 1.5188037934567546 - acc: 0.19403333333333334 - val_acc: 0.1965\n",
      "Epoch 29 / 300 \n",
      " - time (s): 1.7713937759399414 - sq_loss: 0.251873642206192 - tot_loss: 1.378470585506875 - acc: 0.29531666666666667 - val_acc: 0.2953\n",
      "Epoch 30 / 300 \n",
      " - time (s): 1.8779332637786865 - sq_loss: 0.1707916408777237 - tot_loss: 1.2869109419334563 - acc: 0.10168333333333333 - val_acc: 0.1029\n",
      "Epoch 31 / 300 \n",
      " - time (s): 1.8809504508972168 - sq_loss: 0.11590743809938431 - tot_loss: 1.237448698571825 - acc: 0.22623333333333334 - val_acc: 0.2191\n",
      "Epoch 32 / 300 \n",
      " - time (s): 1.8636624813079834 - sq_loss: 0.07870730757713318 - tot_loss: 1.3950163117988268 - acc: 0.31046666666666667 - val_acc: 0.3096\n",
      "Epoch 33 / 300 \n",
      " - time (s): 1.8378410339355469 - sq_loss: 0.05348389223217964 - tot_loss: 1.195157054484298 - acc: 0.16248333333333334 - val_acc: 0.1553\n",
      "Epoch 34 / 300 \n",
      " - time (s): 1.8057634830474854 - sq_loss: 0.03639926388859749 - tot_loss: 1.1047884967156278 - acc: 0.20258333333333334 - val_acc: 0.2082\n",
      "Epoch 35 / 300 \n",
      " - time (s): 1.7813856601715088 - sq_loss: 0.024834292009472847 - tot_loss: 1.2510633447236614 - acc: 0.25093333333333334 - val_acc: 0.2534\n",
      "Epoch 36 / 300 \n",
      " - time (s): 1.8082196712493896 - sq_loss: 0.016967110335826874 - tot_loss: 1.2586941726622172 - acc: 0.3476 - val_acc: 0.3504\n",
      "Epoch 37 / 300 \n",
      " - time (s): 1.898005723953247 - sq_loss: 0.01161525771021843 - tot_loss: 1.1974928191011713 - acc: 0.28185 - val_acc: 0.2925\n",
      "Epoch 38 / 300 \n",
      " - time (s): 1.9803335666656494 - sq_loss: 0.007959038950502872 - tot_loss: 1.3646305172915163 - acc: 0.3248333333333333 - val_acc: 0.318\n",
      "Epoch 39 / 300 \n",
      " - time (s): 1.756176233291626 - sq_loss: 0.005466893315315247 - tot_loss: 1.3045067382809066 - acc: 0.49378333333333335 - val_acc: 0.5017\n",
      "Epoch 40 / 300 \n",
      " - time (s): 1.8332633972167969 - sq_loss: 0.003772343508899212 - tot_loss: 1.0335633401045925 - acc: 0.4296333333333333 - val_acc: 0.4303\n",
      "Epoch 41 / 300 \n",
      " - time (s): 1.7238008975982666 - sq_loss: 0.002609794959425926 - tot_loss: 0.9019721392251085 - acc: 0.46141666666666664 - val_acc: 0.4728\n",
      "Epoch 42 / 300 \n",
      " - time (s): 1.7428069114685059 - sq_loss: 0.001810809480957687 - tot_loss: 0.9678316067220294 - acc: 0.44006666666666666 - val_acc: 0.4433\n",
      "Epoch 43 / 300 \n",
      " - time (s): 1.722656488418579 - sq_loss: 0.0012646085815504193 - tot_loss: 0.9535326503028045 - acc: 0.32813333333333333 - val_acc: 0.3274\n",
      "Epoch 44 / 300 \n",
      " - time (s): 1.739656686782837 - sq_loss: 0.0008871599566191435 - tot_loss: 1.0911090057870751 - acc: 0.28475 - val_acc: 0.2854\n",
      "Epoch 45 / 300 \n",
      " - time (s): 1.8030898571014404 - sq_loss: 0.0006267472053878009 - tot_loss: 0.9542499410526943 - acc: 0.4933666666666667 - val_acc: 0.5175\n",
      "Epoch 46 / 300 \n",
      " - time (s): 1.71807861328125 - sq_loss: 0.00044415771844796836 - tot_loss: 0.9934785692275909 - acc: 0.41741666666666666 - val_acc: 0.4309\n",
      "Epoch 47 / 300 \n",
      " - time (s): 1.7307498455047607 - sq_loss: 0.0003186337125953287 - tot_loss: 0.9167975954187568 - acc: 0.4683333333333333 - val_acc: 0.4701\n",
      "Epoch 48 / 300 \n",
      " - time (s): 1.713243007659912 - sq_loss: 0.00023078577942214906 - tot_loss: 1.3263424070828478 - acc: 0.30233333333333334 - val_acc: 0.3169\n",
      "Epoch 49 / 300 \n",
      " - time (s): 1.7291533946990967 - sq_loss: 0.00016573570610489696 - tot_loss: 1.1135426222463138 - acc: 0.57545 - val_acc: 0.5932\n",
      "Epoch 50 / 300 \n",
      " - time (s): 1.7431304454803467 - sq_loss: 0.00011843425454571843 - tot_loss: 0.9107706418508315 - acc: 0.41735 - val_acc: 0.4206\n",
      "Epoch 51 / 300 \n",
      " - time (s): 1.7943382263183594 - sq_loss: 8.659542800160125e-05 - tot_loss: 1.0190776225135778 - acc: 0.40523333333333333 - val_acc: 0.4216\n",
      "Epoch 52 / 300 \n",
      " - time (s): 1.7112598419189453 - sq_loss: 6.717618816765025e-05 - tot_loss: 1.1747892982311896 - acc: 0.5686166666666667 - val_acc: 0.5717\n",
      "Epoch 53 / 300 \n",
      " - time (s): 1.7232263088226318 - sq_loss: 5.08462471771054e-05 - tot_loss: 1.1828222563999589 - acc: 0.3327 - val_acc: 0.3434\n",
      "Epoch 54 / 300 \n",
      " - time (s): 1.7368462085723877 - sq_loss: 4.0787104808259755e-05 - tot_loss: 1.1629934837365 - acc: 0.54535 - val_acc: 0.5468\n",
      "Epoch 55 / 300 \n",
      " - time (s): 1.7265286445617676 - sq_loss: 3.156396996928379e-05 - tot_loss: 0.9190661857683153 - acc: 0.5100833333333333 - val_acc: 0.5207\n",
      "Epoch 56 / 300 \n",
      " - time (s): 1.7321205139160156 - sq_loss: 2.655740172485821e-05 - tot_loss: 1.0090583335841075 - acc: 0.5332 - val_acc: 0.5484\n",
      "Epoch 57 / 300 \n",
      " - time (s): 1.729041337966919 - sq_loss: 2.0490895622060634e-05 - tot_loss: 0.9841947912591422 - acc: 0.5402166666666667 - val_acc: 0.5419\n",
      "Epoch 58 / 300 \n",
      " - time (s): 1.728452444076538 - sq_loss: 1.7333655705442652e-05 - tot_loss: 0.9323627243757073 - acc: 0.5819333333333333 - val_acc: 0.5841\n",
      "Epoch 59 / 300 \n",
      " - time (s): 1.7203876972198486 - sq_loss: 1.4646921954408754e-05 - tot_loss: 1.0569735763683639 - acc: 0.5671833333333334 - val_acc: 0.5726\n",
      "Epoch 60 / 300 \n",
      " - time (s): 1.744931936264038 - sq_loss: 1.1484594324429054e-05 - tot_loss: 0.9448944138903244 - acc: 0.6144166666666667 - val_acc: 0.6305\n",
      "Epoch 61 / 300 \n",
      " - time (s): 1.7325985431671143 - sq_loss: 1.0000622751249466e-05 - tot_loss: 1.0045102316335033 - acc: 0.6234333333333333 - val_acc: 0.6314\n",
      "Epoch 62 / 300 \n",
      " - time (s): 1.7355005741119385 - sq_loss: 1.4564442608389072e-05 - tot_loss: 0.8972809067108756 - acc: 0.5246833333333333 - val_acc: 0.5442\n",
      "Epoch 63 / 300 \n",
      " - time (s): 1.7242071628570557 - sq_loss: 1.2230810170876794e-05 - tot_loss: 1.0660719778879866 - acc: 0.6274 - val_acc: 0.6372\n",
      "Epoch 64 / 300 \n",
      " - time (s): 1.7244315147399902 - sq_loss: 1.0658253813744523e-05 - tot_loss: 0.8805015668058331 - acc: 0.5988666666666667 - val_acc: 0.6175\n",
      "Epoch 65 / 300 \n",
      " - time (s): 1.805755376815796 - sq_loss: 9.980436516343616e-06 - tot_loss: 0.9318523223400916 - acc: 0.58585 - val_acc: 0.6039\n",
      "Epoch 66 / 300 \n",
      " - time (s): 1.916489601135254 - sq_loss: 6.98708981872187e-06 - tot_loss: 1.126732107288717 - acc: 0.5607166666666666 - val_acc: 0.578\n",
      "Epoch 67 / 300 \n",
      " - time (s): 1.7656874656677246 - sq_loss: 5.678772595274495e-06 - tot_loss: 0.9882530363361184 - acc: 0.5659333333333333 - val_acc: 0.5705\n",
      "Epoch 68 / 300 \n",
      " - time (s): 1.7143867015838623 - sq_loss: 4.695758889283752e-06 - tot_loss: 0.9284786645825989 - acc: 0.69735 - val_acc: 0.7136\n",
      "Epoch 69 / 300 \n",
      " - time (s): 1.7613389492034912 - sq_loss: 4.5961487558088265e-06 - tot_loss: 0.9553562678875096 - acc: 0.5689 - val_acc: 0.5871\n",
      "Epoch 70 / 300 \n",
      " - time (s): 1.7276802062988281 - sq_loss: 4.659672413254157e-06 - tot_loss: 1.0335368692722113 - acc: 0.66195 - val_acc: 0.6695\n",
      "Epoch 71 / 300 \n",
      " - time (s): 1.7208201885223389 - sq_loss: 6.570229288627161e-06 - tot_loss: 0.8696156460205202 - acc: 0.71695 - val_acc: 0.7302\n",
      "Epoch 72 / 300 \n",
      " - time (s): 1.761324167251587 - sq_loss: 4.046683898195624e-06 - tot_loss: 1.0265782427431986 - acc: 0.6532 - val_acc: 0.666\n",
      "Epoch 73 / 300 \n",
      " - time (s): 1.7481403350830078 - sq_loss: 4.659385922423098e-06 - tot_loss: 0.9068883312656908 - acc: 0.6329333333333333 - val_acc: 0.6434\n",
      "Epoch 74 / 300 \n",
      " - time (s): 1.8347034454345703 - sq_loss: 4.484863438847242e-06 - tot_loss: 0.9722833696500857 - acc: 0.60385 - val_acc: 0.6248\n",
      "Epoch 75 / 300 \n",
      " - time (s): 1.8979501724243164 - sq_loss: 4.361208539194195e-06 - tot_loss: 1.313392104369541 - acc: 0.6892333333333334 - val_acc: 0.6995\n",
      "Epoch 76 / 300 \n",
      " - time (s): 1.8443753719329834 - sq_loss: 4.628298484021798e-06 - tot_loss: 0.960592394681953 - acc: 0.6935 - val_acc: 0.7069\n",
      "Epoch 77 / 300 \n",
      " - time (s): 1.7411749362945557 - sq_loss: 3.521875214573811e-06 - tot_loss: 0.8100718062039505 - acc: 0.6895166666666667 - val_acc: 0.7\n",
      "Epoch 78 / 300 \n",
      " - time (s): 1.7997121810913086 - sq_loss: 2.9151381113479147e-06 - tot_loss: 0.8201337540324403 - acc: 0.6547666666666667 - val_acc: 0.6713\n",
      "Epoch 79 / 300 \n",
      " - time (s): 1.752974271774292 - sq_loss: 3.498026444503921e-06 - tot_loss: 0.8759604874583147 - acc: 0.6649333333333334 - val_acc: 0.6793\n",
      "Epoch 80 / 300 \n",
      " - time (s): 1.7522313594818115 - sq_loss: 2.8548738555400632e-06 - tot_loss: 0.8162807802673342 - acc: 0.6200666666666667 - val_acc: 0.6379\n",
      "Epoch 81 / 300 \n",
      " - time (s): 1.7730956077575684 - sq_loss: 5.729911663365783e-06 - tot_loss: 0.9210597251517356 - acc: 0.6599333333333334 - val_acc: 0.6752\n",
      "Epoch 82 / 300 \n",
      " - time (s): 1.808532953262329 - sq_loss: 6.798651156714186e-06 - tot_loss: 0.870269098710196 - acc: 0.6202333333333333 - val_acc: 0.6397\n",
      "Epoch 83 / 300 \n",
      " - time (s): 1.7483229637145996 - sq_loss: 2.5561414531694027e-06 - tot_loss: 0.9198443462348678 - acc: 0.69595 - val_acc: 0.7067\n",
      "Epoch 84 / 300 \n",
      " - time (s): 1.8013780117034912 - sq_loss: 2.445546670060139e-06 - tot_loss: 0.965849123438602 - acc: 0.6815 - val_acc: 0.6949\n",
      "Epoch 85 / 300 \n",
      " - time (s): 1.880711317062378 - sq_loss: 2.9724508294748375e-06 - tot_loss: 0.8627560865736541 - acc: 0.6927166666666666 - val_acc: 0.7108\n",
      "Epoch 86 / 300 \n",
      " - time (s): 1.7380225658416748 - sq_loss: 2.6491145490581403e-06 - tot_loss: 0.9037755568517696 - acc: 0.69095 - val_acc: 0.71\n",
      "Epoch 87 / 300 \n",
      " - time (s): 1.7220511436462402 - sq_loss: 2.21016421164677e-06 - tot_loss: 0.9600718108433739 - acc: 0.6622166666666667 - val_acc: 0.6741\n",
      "Epoch 88 / 300 \n",
      " - time (s): 1.728649616241455 - sq_loss: 2.112411721100216e-06 - tot_loss: 0.9485415942083364 - acc: 0.7130666666666666 - val_acc: 0.7328\n",
      "Epoch 89 / 300 \n",
      " - time (s): 1.7306485176086426 - sq_loss: 2.1047731024737004e-06 - tot_loss: 1.079372129827334 - acc: 0.6659166666666667 - val_acc: 0.6822\n",
      "Epoch 90 / 300 \n",
      " - time (s): 1.722517728805542 - sq_loss: 1.8442372038407484e-06 - tot_loss: 1.0044835408555173 - acc: 0.6986 - val_acc: 0.7146\n",
      "Epoch 91 / 300 \n",
      " - time (s): 1.7341625690460205 - sq_loss: 1.973048256331822e-06 - tot_loss: 1.099418087291724 - acc: 0.7460666666666667 - val_acc: 0.7566\n",
      "Epoch 92 / 300 \n",
      " - time (s): 1.7130684852600098 - sq_loss: 2.6470579541637562e-06 - tot_loss: 0.985802375651474 - acc: 0.7421166666666666 - val_acc: 0.7571\n",
      "Epoch 93 / 300 \n",
      " - time (s): 1.7117302417755127 - sq_loss: 2.503412815713091e-06 - tot_loss: 1.1599777030473888 - acc: 0.7070666666666666 - val_acc: 0.7161\n",
      "Epoch 94 / 300 \n",
      " - time (s): 1.7239670753479004 - sq_loss: 2.2875299237057334e-06 - tot_loss: 0.9923800787744312 - acc: 0.7009 - val_acc: 0.7164\n",
      "Epoch 95 / 300 \n",
      " - time (s): 1.7271206378936768 - sq_loss: 1.7108978909163852e-06 - tot_loss: 1.0199436973599632 - acc: 0.7042166666666667 - val_acc: 0.7172\n",
      "Epoch 96 / 300 \n",
      " - time (s): 1.7305090427398682 - sq_loss: 1.8495212543712114e-06 - tot_loss: 0.9390614895984299 - acc: 0.7118 - val_acc: 0.7302\n",
      "Epoch 97 / 300 \n",
      " - time (s): 1.731172800064087 - sq_loss: 1.7893485164677259e-06 - tot_loss: 0.9588919081265885 - acc: 0.75035 - val_acc: 0.7568\n",
      "Epoch 98 / 300 \n",
      " - time (s): 1.7101235389709473 - sq_loss: 1.7374615026710671e-06 - tot_loss: 0.8358358055621693 - acc: 0.7227833333333333 - val_acc: 0.7349\n",
      "Epoch 99 / 300 \n",
      " - time (s): 1.725045919418335 - sq_loss: 2.582232355052838e-06 - tot_loss: 0.9279970504817356 - acc: 0.7518333333333334 - val_acc: 0.7662\n",
      "Epoch 100 / 300 \n",
      " - time (s): 1.7166392803192139 - sq_loss: 1.6367328043997986e-06 - tot_loss: 0.9176585002921911 - acc: 0.7242 - val_acc: 0.7383\n",
      "Epoch 101 / 300 \n",
      " - time (s): 1.7404160499572754 - sq_loss: 1.4981849290052196e-06 - tot_loss: 0.7986795694321245 - acc: 0.7371333333333333 - val_acc: 0.7584\n",
      "Epoch 102 / 300 \n",
      " - time (s): 1.7283332347869873 - sq_loss: 6.402454800991109e-06 - tot_loss: 0.9464093890778713 - acc: 0.7010833333333333 - val_acc: 0.7169\n",
      "Epoch 103 / 300 \n",
      " - time (s): 1.721280574798584 - sq_loss: 5.089178557682317e-06 - tot_loss: 0.8351459427676673 - acc: 0.7348166666666667 - val_acc: 0.7469\n",
      "Epoch 104 / 300 \n",
      " - time (s): 1.7351388931274414 - sq_loss: 5.884342044737423e-06 - tot_loss: 0.9562856372581336 - acc: 0.73015 - val_acc: 0.7482\n",
      "Epoch 105 / 300 \n",
      " - time (s): 1.7371792793273926 - sq_loss: 2.257648475278984e-06 - tot_loss: 0.998437645898548 - acc: 0.7346166666666667 - val_acc: 0.7502\n",
      "Epoch 106 / 300 \n",
      " - time (s): 1.7200953960418701 - sq_loss: 1.6307519672409398e-06 - tot_loss: 0.8718093348641105 - acc: 0.7238166666666667 - val_acc: 0.7429\n",
      "Epoch 107 / 300 \n",
      " - time (s): 1.7310066223144531 - sq_loss: 1.9712986158992862e-06 - tot_loss: 0.8615493321792655 - acc: 0.7279333333333333 - val_acc: 0.7417\n",
      "Epoch 108 / 300 \n",
      " - time (s): 1.722571849822998 - sq_loss: 3.3280518891842803e-06 - tot_loss: 0.9665853297026388 - acc: 0.7258166666666667 - val_acc: 0.7431\n",
      "Epoch 109 / 300 \n",
      " - time (s): 1.7466883659362793 - sq_loss: 1.234980118169915e-06 - tot_loss: 0.9506733517082466 - acc: 0.7749166666666667 - val_acc: 0.7818\n",
      "Epoch 110 / 300 \n",
      " - time (s): 1.7702841758728027 - sq_loss: 1.8581788481242256e-06 - tot_loss: 0.8744554544175571 - acc: 0.7242333333333333 - val_acc: 0.743\n",
      "Epoch 111 / 300 \n",
      " - time (s): 1.73309326171875 - sq_loss: 1.7533501477373648e-06 - tot_loss: 0.8684351580058092 - acc: 0.7718166666666667 - val_acc: 0.7833\n",
      "Epoch 112 / 300 \n",
      " - time (s): 1.7214155197143555 - sq_loss: 1.6456203866255237e-06 - tot_loss: 0.8067532267839397 - acc: 0.7453333333333333 - val_acc: 0.7651\n",
      "Epoch 113 / 300 \n",
      " - time (s): 1.7202880382537842 - sq_loss: 1.4913879340383573e-06 - tot_loss: 0.8815452899419824 - acc: 0.7559 - val_acc: 0.7721\n",
      "Epoch 114 / 300 \n",
      " - time (s): 1.7258477210998535 - sq_loss: 4.3290660869388375e-06 - tot_loss: 0.8381538154485497 - acc: 0.7666666666666667 - val_acc: 0.7814\n",
      "Epoch 115 / 300 \n",
      " - time (s): 1.7214839458465576 - sq_loss: 3.7014606277807616e-06 - tot_loss: 0.7723147645147037 - acc: 0.7581333333333333 - val_acc: 0.7726\n",
      "Epoch 116 / 300 \n",
      " - time (s): 1.7312006950378418 - sq_loss: 3.6653311781265074e-06 - tot_loss: 0.8457140936864107 - acc: 0.7652166666666667 - val_acc: 0.779\n",
      "Epoch 117 / 300 \n",
      " - time (s): 1.7079627513885498 - sq_loss: 4.843503120355308e-06 - tot_loss: 0.9053289625226171 - acc: 0.7256 - val_acc: 0.7401\n",
      "Epoch 118 / 300 \n",
      " - time (s): 1.7206835746765137 - sq_loss: 4.089388767170021e-06 - tot_loss: 0.8989255282472186 - acc: 0.7832666666666667 - val_acc: 0.7977\n",
      "Epoch 119 / 300 \n",
      " - time (s): 1.7331063747406006 - sq_loss: 4.99936095366138e-06 - tot_loss: 0.8825283527389729 - acc: 0.7620166666666667 - val_acc: 0.7782\n",
      "Epoch 120 / 300 \n",
      " - time (s): 1.7351787090301514 - sq_loss: 5.688668352377135e-06 - tot_loss: 0.9330194709218631 - acc: 0.7561833333333333 - val_acc: 0.7722\n",
      "Epoch 121 / 300 \n",
      " - time (s): 1.7313752174377441 - sq_loss: 4.188489583611954e-06 - tot_loss: 0.9593834451288785 - acc: 0.7752666666666667 - val_acc: 0.7865\n",
      "Epoch 122 / 300 \n",
      " - time (s): 1.721740484237671 - sq_loss: 3.0244659683376085e-06 - tot_loss: 1.0465001854568072 - acc: 0.7667166666666667 - val_acc: 0.7817\n",
      "Epoch 123 / 300 \n",
      " - time (s): 1.7191121578216553 - sq_loss: 2.4695214051462244e-06 - tot_loss: 0.9717759618247328 - acc: 0.7728333333333334 - val_acc: 0.788\n",
      "Epoch 124 / 300 \n",
      " - time (s): 1.7291152477264404 - sq_loss: 1.3316996501089307e-06 - tot_loss: 0.8385786832616304 - acc: 0.7748666666666667 - val_acc: 0.7916\n",
      "Epoch 125 / 300 \n",
      " - time (s): 1.7241265773773193 - sq_loss: 1.8273588011652464e-06 - tot_loss: 0.8606795617399712 - acc: 0.7888833333333334 - val_acc: 0.8028\n",
      "Epoch 126 / 300 \n",
      " - time (s): 1.7286646366119385 - sq_loss: 2.7973467240371974e-06 - tot_loss: 0.9276312768427033 - acc: 0.7838666666666667 - val_acc: 0.7976\n",
      "Epoch 127 / 300 \n",
      " - time (s): 1.7241511344909668 - sq_loss: 1.0409728474769508e-06 - tot_loss: 0.8645660786758071 - acc: 0.75475 - val_acc: 0.7683\n",
      "Epoch 128 / 300 \n",
      " - time (s): 1.7370707988739014 - sq_loss: 1.2051112889821525e-06 - tot_loss: 0.821593549635395 - acc: 0.7821333333333333 - val_acc: 0.7962\n",
      "Epoch 129 / 300 \n",
      " - time (s): 1.7405333518981934 - sq_loss: 1.2754526323988102e-06 - tot_loss: 0.9813143319379378 - acc: 0.77505 - val_acc: 0.7888\n",
      "Epoch 130 / 300 \n",
      " - time (s): 1.7138266563415527 - sq_loss: 3.341340288898209e-06 - tot_loss: 0.8524373363056839 - acc: 0.7909 - val_acc: 0.8018\n",
      "Epoch 131 / 300 \n",
      " - time (s): 1.7220354080200195 - sq_loss: 2.9138914214854594e-06 - tot_loss: 0.8683473421310737 - acc: 0.76545 - val_acc: 0.7795\n",
      "Epoch 132 / 300 \n",
      " - time (s): 1.7323105335235596 - sq_loss: 1.065181209014554e-06 - tot_loss: 0.8765627048397846 - acc: 0.7828166666666667 - val_acc: 0.7977\n",
      "Epoch 133 / 300 \n",
      " - time (s): 1.736692190170288 - sq_loss: 1.6793388795122155e-06 - tot_loss: 0.865484264596148 - acc: 0.77825 - val_acc: 0.7906\n",
      "Epoch 134 / 300 \n",
      " - time (s): 1.732424259185791 - sq_loss: 2.0582090201060055e-06 - tot_loss: 0.8532113858534558 - acc: 0.7584666666666666 - val_acc: 0.7713\n",
      "Epoch 135 / 300 \n",
      " - time (s): 1.7271208763122559 - sq_loss: 1.382201162414276e-06 - tot_loss: 0.7737687123610613 - acc: 0.8005666666666666 - val_acc: 0.8127\n",
      "Epoch 136 / 300 \n",
      " - time (s): 1.7329893112182617 - sq_loss: 1.53759685872501e-06 - tot_loss: 0.8007988559080559 - acc: 0.7896 - val_acc: 0.798\n",
      "Epoch 137 / 300 \n",
      " - time (s): 1.7193522453308105 - sq_loss: 1.1605037570916465e-06 - tot_loss: 0.8524262980330377 - acc: 0.7653833333333333 - val_acc: 0.7791\n",
      "Epoch 138 / 300 \n",
      " - time (s): 1.7231686115264893 - sq_loss: 1.3408088079813751e-06 - tot_loss: 0.8769240685750219 - acc: 0.79675 - val_acc: 0.8066\n",
      "Epoch 139 / 300 \n",
      " - time (s): 1.7109415531158447 - sq_loss: 1.7343934359814739e-06 - tot_loss: 0.9298026716376171 - acc: 0.7505 - val_acc: 0.766\n",
      "Epoch 140 / 300 \n",
      " - time (s): 1.7168805599212646 - sq_loss: 2.3240070277097402e-06 - tot_loss: 0.858653317371818 - acc: 0.7752833333333333 - val_acc: 0.7857\n",
      "Epoch 141 / 300 \n",
      " - time (s): 1.7288234233856201 - sq_loss: 1.6992034943541512e-06 - tot_loss: 0.9239856636613695 - acc: 0.7633833333333333 - val_acc: 0.7816\n",
      "Epoch 142 / 300 \n",
      " - time (s): 1.8562169075012207 - sq_loss: 2.4030091481108684e-06 - tot_loss: 0.9333506060288528 - acc: 0.80685 - val_acc: 0.8179\n",
      "Epoch 143 / 300 \n",
      " - time (s): 1.8156638145446777 - sq_loss: 1.3052740541752428e-06 - tot_loss: 0.829747326701181 - acc: 0.7963166666666667 - val_acc: 0.8068\n",
      "Epoch 144 / 300 \n",
      " - time (s): 1.876133918762207 - sq_loss: 1.1859831374749774e-06 - tot_loss: 0.8222810387180743 - acc: 0.8040166666666667 - val_acc: 0.8168\n",
      "Epoch 145 / 300 \n",
      " - time (s): 1.8761651515960693 - sq_loss: 1.9726367099792697e-06 - tot_loss: 0.9333384952888082 - acc: 0.7918333333333333 - val_acc: 0.8043\n",
      "Epoch 146 / 300 \n",
      " - time (s): 1.8016879558563232 - sq_loss: 3.3487228847661754e-06 - tot_loss: 0.889267511699245 - acc: 0.80185 - val_acc: 0.8108\n",
      "Epoch 147 / 300 \n",
      " - time (s): 1.8177344799041748 - sq_loss: 1.4298550468083704e-06 - tot_loss: 0.8446565255619589 - acc: 0.8044166666666667 - val_acc: 0.8163\n",
      "Epoch 148 / 300 \n",
      " - time (s): 1.8732209205627441 - sq_loss: 1.4006376432007528e-06 - tot_loss: 0.8834743364544693 - acc: 0.80265 - val_acc: 0.8127\n",
      "Epoch 149 / 300 \n",
      " - time (s): 1.866969108581543 - sq_loss: 1.0593357728794217e-06 - tot_loss: 0.7597547682134973 - acc: 0.8013 - val_acc: 0.8127\n",
      "Epoch 150 / 300 \n",
      " - time (s): 1.9035356044769287 - sq_loss: 1.167494247056311e-06 - tot_loss: 0.8467951884026661 - acc: 0.7896333333333333 - val_acc: 0.7993\n",
      "Epoch 151 / 300 \n",
      " - time (s): 1.8635263442993164 - sq_loss: 1.0908897820627317e-06 - tot_loss: 0.9057536453819921 - acc: 0.7905333333333333 - val_acc: 0.8026\n",
      "Epoch 152 / 300 \n",
      " - time (s): 1.88315749168396 - sq_loss: 3.520957079672371e-06 - tot_loss: 0.9466552520209461 - acc: 0.7988166666666666 - val_acc: 0.8106\n",
      "Epoch 153 / 300 \n",
      " - time (s): 1.8068888187408447 - sq_loss: 2.6409334168420173e-06 - tot_loss: 0.9309072237310829 - acc: 0.8052666666666667 - val_acc: 0.8163\n",
      "Epoch 154 / 300 \n",
      " - time (s): 1.7446436882019043 - sq_loss: 1.7697770999802742e-06 - tot_loss: 0.8772146014239297 - acc: 0.8129166666666666 - val_acc: 0.8238\n",
      "Epoch 155 / 300 \n",
      " - time (s): 1.7535476684570312 - sq_loss: 1.1613615242822561e-06 - tot_loss: 0.9183835880489823 - acc: 0.8108666666666666 - val_acc: 0.8233\n",
      "Epoch 156 / 300 \n",
      " - time (s): 1.9687018394470215 - sq_loss: 1.0195624327025143e-06 - tot_loss: 0.8965123074638086 - acc: 0.8077333333333333 - val_acc: 0.8172\n",
      "Epoch 157 / 300 \n",
      " - time (s): 1.7283282279968262 - sq_loss: 2.2166500457387883e-06 - tot_loss: 0.9194308231276409 - acc: 0.8026 - val_acc: 0.8113\n",
      "Epoch 158 / 300 \n",
      " - time (s): 1.7453513145446777 - sq_loss: 6.943785592739005e-06 - tot_loss: 0.7890451123757884 - acc: 0.7966 - val_acc: 0.8068\n",
      "Epoch 159 / 300 \n",
      " - time (s): 1.7318263053894043 - sq_loss: 1.1555547644093167e-05 - tot_loss: 0.8722957927748212 - acc: 0.7985 - val_acc: 0.8095\n",
      "Epoch 160 / 300 \n",
      " - time (s): 1.7884268760681152 - sq_loss: 6.995739568083081e-06 - tot_loss: 0.8420871711259679 - acc: 0.79735 - val_acc: 0.8085\n",
      "Epoch 161 / 300 \n",
      " - time (s): 1.7377493381500244 - sq_loss: 3.6194273889122996e-06 - tot_loss: 0.7865748776252985 - acc: 0.7900333333333334 - val_acc: 0.804\n",
      "Epoch 162 / 300 \n",
      " - time (s): 1.745887041091919 - sq_loss: 2.532112148401211e-06 - tot_loss: 0.8418396890072017 - acc: 0.7984166666666667 - val_acc: 0.8117\n",
      "Epoch 163 / 300 \n",
      " - time (s): 1.7394993305206299 - sq_loss: 2.0990687517041806e-06 - tot_loss: 0.7892320660016594 - acc: 0.8136666666666666 - val_acc: 0.8255\n",
      "Epoch 164 / 300 \n",
      " - time (s): 1.7280926704406738 - sq_loss: 2.4691032649570843e-06 - tot_loss: 0.8765955678634327 - acc: 0.7981333333333334 - val_acc: 0.8092\n",
      "Epoch 165 / 300 \n",
      " - time (s): 1.7757129669189453 - sq_loss: 2.7600272005656734e-06 - tot_loss: 0.9171015266374525 - acc: 0.78785 - val_acc: 0.799\n",
      "Epoch 166 / 300 \n",
      " - time (s): 1.9510118961334229 - sq_loss: 3.6311926123744342e-06 - tot_loss: 0.8575011936031842 - acc: 0.7858333333333334 - val_acc: 0.7964\n",
      "Epoch 167 / 300 \n",
      " - time (s): 1.857062578201294 - sq_loss: 3.809163217738387e-06 - tot_loss: 0.8656326057127899 - acc: 0.8023 - val_acc: 0.8163\n",
      "Epoch 168 / 300 \n",
      " - time (s): 1.7435884475708008 - sq_loss: 4.2953734009643085e-06 - tot_loss: 0.7421617942427474 - acc: 0.8029166666666666 - val_acc: 0.8131\n",
      "Epoch 169 / 300 \n",
      " - time (s): 1.8566303253173828 - sq_loss: 1.3357007446757052e-06 - tot_loss: 0.8231163685709362 - acc: 0.7923333333333333 - val_acc: 0.8055\n",
      "Epoch 170 / 300 \n",
      " - time (s): 1.9631531238555908 - sq_loss: 3.37492110702442e-06 - tot_loss: 0.9759049230278833 - acc: 0.81755 - val_acc: 0.83\n",
      "Epoch 171 / 300 \n",
      " - time (s): 1.8551347255706787 - sq_loss: 2.503078349036514e-06 - tot_loss: 1.0403574437548286 - acc: 0.8153 - val_acc: 0.8274\n",
      "Epoch 172 / 300 \n",
      " - time (s): 1.8006501197814941 - sq_loss: 1.2535651876532938e-06 - tot_loss: 0.9495827776459009 - acc: 0.7980333333333334 - val_acc: 0.8083\n",
      "Epoch 173 / 300 \n",
      " - time (s): 1.8509776592254639 - sq_loss: 2.201074948970927e-06 - tot_loss: 0.8606326403637468 - acc: 0.8148666666666666 - val_acc: 0.8267\n",
      "Epoch 174 / 300 \n",
      " - time (s): 1.7223494052886963 - sq_loss: 3.806190306931967e-06 - tot_loss: 0.893905484849256 - acc: 0.8125166666666667 - val_acc: 0.8225\n",
      "Epoch 175 / 300 \n",
      " - time (s): 1.7227864265441895 - sq_loss: 1.9568585685192375e-06 - tot_loss: 1.1692725418085956 - acc: 0.8281 - val_acc: 0.839\n",
      "Epoch 176 / 300 \n",
      " - time (s): 1.7272069454193115 - sq_loss: 1.3354957673072931e-06 - tot_loss: 0.9743793482858791 - acc: 0.8060166666666667 - val_acc: 0.819\n",
      "Epoch 177 / 300 \n",
      " - time (s): 1.7884976863861084 - sq_loss: 1.3826509075443028e-06 - tot_loss: 0.8484381164923889 - acc: 0.8254333333333334 - val_acc: 0.8362\n",
      "Epoch 178 / 300 \n",
      " - time (s): 1.7556097507476807 - sq_loss: 1.8715992382567492e-06 - tot_loss: 0.7403708116154348 - acc: 0.8061 - val_acc: 0.8172\n",
      "Epoch 179 / 300 \n",
      " - time (s): 1.7342610359191895 - sq_loss: 2.7459209377411753e-06 - tot_loss: 0.7874275262693118 - acc: 0.8201833333333334 - val_acc: 0.8296\n",
      "Epoch 180 / 300 \n",
      " - time (s): 1.734070062637329 - sq_loss: 2.7129844966111705e-06 - tot_loss: 0.8154527662682085 - acc: 0.8148 - val_acc: 0.8292\n",
      "Epoch 181 / 300 \n",
      " - time (s): 1.8354060649871826 - sq_loss: 2.082561877614353e-06 - tot_loss: 0.9395932404067935 - acc: 0.8142 - val_acc: 0.8289\n",
      "Epoch 182 / 300 \n",
      " - time (s): 1.7621219158172607 - sq_loss: 2.6017287382273935e-06 - tot_loss: 0.7776068555449456 - acc: 0.8164 - val_acc: 0.8281\n",
      "Epoch 183 / 300 \n",
      " - time (s): 1.8719313144683838 - sq_loss: 2.7101980322186137e-06 - tot_loss: 0.8566104230606015 - acc: 0.8076333333333333 - val_acc: 0.8187\n",
      "Epoch 184 / 300 \n",
      " - time (s): 1.8176767826080322 - sq_loss: 2.4961759663710836e-06 - tot_loss: 0.719433768863837 - acc: 0.8187833333333333 - val_acc: 0.831\n",
      "Epoch 185 / 300 \n",
      " - time (s): 1.736008644104004 - sq_loss: 1.8379855646344367e-06 - tot_loss: 0.775491399798284 - acc: 0.8219833333333333 - val_acc: 0.8316\n",
      "Epoch 186 / 300 \n",
      " - time (s): 1.7359097003936768 - sq_loss: 1.726314394545625e-06 - tot_loss: 0.7595584344587678 - acc: 0.8148333333333333 - val_acc: 0.8296\n",
      "Epoch 187 / 300 \n",
      " - time (s): 1.8443310260772705 - sq_loss: 2.998920763275237e-06 - tot_loss: 0.8075910039408427 - acc: 0.81615 - val_acc: 0.8302\n",
      "Epoch 188 / 300 \n",
      " - time (s): 1.9835386276245117 - sq_loss: 1.3321958931555855e-06 - tot_loss: 0.80989330451564 - acc: 0.8102833333333334 - val_acc: 0.8245\n",
      "Epoch 189 / 300 \n",
      " - time (s): 1.9412519931793213 - sq_loss: 1.664136675572081e-06 - tot_loss: 0.8620193099283142 - acc: 0.8141166666666667 - val_acc: 0.8263\n",
      "Epoch 190 / 300 \n",
      " - time (s): 1.8835577964782715 - sq_loss: 1.4901569329595077e-06 - tot_loss: 0.9264191803348467 - acc: 0.8123 - val_acc: 0.824\n",
      "Epoch 191 / 300 \n",
      " - time (s): 1.91768479347229 - sq_loss: 1.503020371274033e-06 - tot_loss: 0.9096456056289526 - acc: 0.82835 - val_acc: 0.8391\n",
      "Epoch 192 / 300 \n",
      " - time (s): 1.744835376739502 - sq_loss: 4.816698492504656e-06 - tot_loss: 1.0869125949175213 - acc: 0.8081166666666667 - val_acc: 0.8198\n",
      "Epoch 193 / 300 \n",
      " - time (s): 1.7709970474243164 - sq_loss: 2.907727548517869e-06 - tot_loss: 0.9218129623407094 - acc: 0.8299833333333333 - val_acc: 0.8412\n",
      "Epoch 194 / 300 \n",
      " - time (s): 1.8877098560333252 - sq_loss: 1.2068265959896962e-06 - tot_loss: 0.79042472430217 - acc: 0.8066166666666666 - val_acc: 0.8219\n",
      "Epoch 195 / 300 \n",
      " - time (s): 1.856348991394043 - sq_loss: 2.9939199066575384e-06 - tot_loss: 0.9576695615703557 - acc: 0.8265166666666667 - val_acc: 0.838\n",
      "Epoch 196 / 300 \n",
      " - time (s): 1.9623208045959473 - sq_loss: 4.737178642244544e-06 - tot_loss: 0.8215711377879416 - acc: 0.8107333333333333 - val_acc: 0.8248\n",
      "Epoch 197 / 300 \n",
      " - time (s): 1.768545389175415 - sq_loss: 2.553653075665352e-06 - tot_loss: 0.8304931242194016 - acc: 0.8266833333333333 - val_acc: 0.8393\n",
      "Epoch 198 / 300 \n",
      " - time (s): 1.7624297142028809 - sq_loss: 2.481475803506328e-06 - tot_loss: 0.884494989353243 - acc: 0.8153 - val_acc: 0.8271\n",
      "Epoch 199 / 300 \n",
      " - time (s): 1.8578953742980957 - sq_loss: 3.3015053304552566e-06 - tot_loss: 0.9132971863759849 - acc: 0.8172333333333334 - val_acc: 0.8296\n",
      "Epoch 200 / 300 \n",
      " - time (s): 2.2551348209381104 - sq_loss: 2.510118747522938e-06 - tot_loss: 0.9800158543228008 - acc: 0.83225 - val_acc: 0.8435\n",
      "Epoch 201 / 300 \n",
      " - time (s): 1.8818089962005615 - sq_loss: 5.202288775763009e-06 - tot_loss: 0.8318064353334194 - acc: 0.8266666666666667 - val_acc: 0.8394\n",
      "Epoch 202 / 300 \n",
      " - time (s): 1.864593744277954 - sq_loss: 1.7082116983146989e-06 - tot_loss: 0.8704293169927269 - acc: 0.8315 - val_acc: 0.84\n",
      "Epoch 203 / 300 \n",
      " - time (s): 1.8431153297424316 - sq_loss: 1.7740262592269573e-06 - tot_loss: 1.0156381835863613 - acc: 0.8194333333333333 - val_acc: 0.8321\n",
      "Epoch 204 / 300 \n",
      " - time (s): 1.7900269031524658 - sq_loss: 5.556768883252516e-06 - tot_loss: 0.9301221981531853 - acc: 0.8219333333333333 - val_acc: 0.8341\n",
      "Epoch 205 / 300 \n",
      " - time (s): 1.9166057109832764 - sq_loss: 2.2936146706342697e-06 - tot_loss: 0.8023819834743335 - acc: 0.83725 - val_acc: 0.8445\n",
      "Epoch 206 / 300 \n",
      " - time (s): 1.9266705513000488 - sq_loss: 2.211925220763078e-06 - tot_loss: 0.7843352524409966 - acc: 0.8310666666666666 - val_acc: 0.8404\n",
      "Epoch 207 / 300 \n",
      " - time (s): 1.8701460361480713 - sq_loss: 1.239467792402138e-06 - tot_loss: 0.9340599306081003 - acc: 0.8361833333333333 - val_acc: 0.846\n",
      "Epoch 208 / 300 \n",
      " - time (s): 1.9267637729644775 - sq_loss: 1.3059027423878433e-06 - tot_loss: 0.9029697478383696 - acc: 0.8184333333333333 - val_acc: 0.8314\n",
      "Epoch 209 / 300 \n",
      " - time (s): 1.878441572189331 - sq_loss: 1.798880930437008e-06 - tot_loss: 0.9365043132988831 - acc: 0.8289166666666666 - val_acc: 0.8414\n",
      "Epoch 210 / 300 \n",
      " - time (s): 1.9102861881256104 - sq_loss: 2.208724708907539e-06 - tot_loss: 0.7930469653724685 - acc: 0.8308333333333333 - val_acc: 0.8421\n",
      "Epoch 211 / 300 \n",
      " - time (s): 1.8745861053466797 - sq_loss: 1.348302703263471e-06 - tot_loss: 0.8563238214796911 - acc: 0.8247666666666666 - val_acc: 0.8373\n",
      "Epoch 212 / 300 \n",
      " - time (s): 1.9740266799926758 - sq_loss: 1.1376286011000047e-06 - tot_loss: 0.8229519344130267 - acc: 0.8395666666666667 - val_acc: 0.8486\n",
      "Epoch 213 / 300 \n",
      " - time (s): 1.9582765102386475 - sq_loss: 2.5609717795305187e-06 - tot_loss: 1.0568246348013872 - acc: 0.8170666666666667 - val_acc: 0.8316\n",
      "Epoch 214 / 300 \n",
      " - time (s): 1.958897590637207 - sq_loss: 3.2824552818055963e-06 - tot_loss: 0.8154737664897311 - acc: 0.8276833333333333 - val_acc: 0.838\n",
      "Epoch 215 / 300 \n",
      " - time (s): 1.9330248832702637 - sq_loss: 2.4237458546849666e-06 - tot_loss: 0.8292423065802268 - acc: 0.8180666666666667 - val_acc: 0.8289\n",
      "Epoch 216 / 300 \n",
      " - time (s): 1.9357435703277588 - sq_loss: 1.7225022475031437e-06 - tot_loss: 0.8345870221012319 - acc: 0.8315833333333333 - val_acc: 0.842\n",
      "Epoch 217 / 300 \n",
      " - time (s): 1.9618608951568604 - sq_loss: 1.6483288618474035e-06 - tot_loss: 0.9316240828491118 - acc: 0.8248833333333333 - val_acc: 0.8357\n",
      "Epoch 218 / 300 \n",
      " - time (s): 1.773179531097412 - sq_loss: 1.1873679568452644e-06 - tot_loss: 1.015340215514584 - acc: 0.8312666666666667 - val_acc: 0.8422\n",
      "Epoch 219 / 300 \n",
      " - time (s): 1.7481451034545898 - sq_loss: 9.880768629955128e-07 - tot_loss: 0.9599450637051632 - acc: 0.83545 - val_acc: 0.8449\n",
      "Epoch 220 / 300 \n",
      " - time (s): 1.769653558731079 - sq_loss: 1.1458328117441852e-06 - tot_loss: 0.9784021540913272 - acc: 0.8263333333333334 - val_acc: 0.8391\n",
      "Epoch 221 / 300 \n",
      " - time (s): 1.7615139484405518 - sq_loss: 2.9639495551236905e-06 - tot_loss: 0.8928482534911382 - acc: 0.8371166666666666 - val_acc: 0.8473\n",
      "Epoch 222 / 300 \n",
      " - time (s): 1.8039789199829102 - sq_loss: 1.572084215695213e-06 - tot_loss: 0.95187995474123 - acc: 0.8328833333333333 - val_acc: 0.8437\n",
      "Epoch 223 / 300 \n",
      " - time (s): 1.8480963706970215 - sq_loss: 2.7338376185070956e-06 - tot_loss: 0.8804676905886026 - acc: 0.8348666666666666 - val_acc: 0.8465\n",
      "Epoch 224 / 300 \n",
      " - time (s): 1.8929381370544434 - sq_loss: 1.371619987367012e-06 - tot_loss: 0.8362538892980638 - acc: 0.8305333333333333 - val_acc: 0.8427\n",
      "Epoch 225 / 300 \n",
      " - time (s): 1.8208129405975342 - sq_loss: 1.1210659067728557e-06 - tot_loss: 0.9732039410237121 - acc: 0.8332166666666667 - val_acc: 0.8442\n",
      "Epoch 226 / 300 \n",
      " - time (s): 1.8586199283599854 - sq_loss: 1.65865742474125e-06 - tot_loss: 0.7965504071518126 - acc: 0.8330166666666666 - val_acc: 0.8446\n",
      "Epoch 227 / 300 \n",
      " - time (s): 1.8747172355651855 - sq_loss: 4.268571046850411e-06 - tot_loss: 0.8096193767337354 - acc: 0.8323666666666667 - val_acc: 0.843\n",
      "Epoch 228 / 300 \n",
      " - time (s): 1.786515712738037 - sq_loss: 8.458755473839119e-06 - tot_loss: 0.8826974457988399 - acc: 0.8364166666666667 - val_acc: 0.8476\n",
      "Epoch 229 / 300 \n",
      " - time (s): 1.8193492889404297 - sq_loss: 4.980442099622451e-06 - tot_loss: 0.923963434097459 - acc: 0.8332 - val_acc: 0.8446\n",
      "Epoch 230 / 300 \n",
      " - time (s): 1.8597304821014404 - sq_loss: 1.898584400805703e-06 - tot_loss: 0.923689328100977 - acc: 0.8243666666666667 - val_acc: 0.8328\n",
      "Epoch 231 / 300 \n",
      " - time (s): 1.8663654327392578 - sq_loss: 3.8662315091642085e-06 - tot_loss: 1.0487651338694377 - acc: 0.8314833333333334 - val_acc: 0.8451\n",
      "Epoch 232 / 300 \n",
      " - time (s): 1.8064045906066895 - sq_loss: 2.1820355868840124e-06 - tot_loss: 0.7619121172497216 - acc: 0.8395833333333333 - val_acc: 0.8525\n",
      "Epoch 233 / 300 \n",
      " - time (s): 1.7664060592651367 - sq_loss: 1.6940758769123931e-06 - tot_loss: 0.7318582751978511 - acc: 0.8337166666666667 - val_acc: 0.8458\n",
      "Epoch 234 / 300 \n",
      " - time (s): 1.7383999824523926 - sq_loss: 1.2080668057024013e-06 - tot_loss: 0.905682406631513 - acc: 0.8392 - val_acc: 0.8496\n",
      "Epoch 235 / 300 \n",
      " - time (s): 1.7751023769378662 - sq_loss: 2.1743976503785234e-06 - tot_loss: 0.9064121452151994 - acc: 0.8322333333333334 - val_acc: 0.8444\n",
      "Epoch 236 / 300 \n",
      " - time (s): 1.8169586658477783 - sq_loss: 1.1742014294213732e-06 - tot_loss: 0.7432306792726422 - acc: 0.8314666666666667 - val_acc: 0.8436\n",
      "Epoch 237 / 300 \n",
      " - time (s): 1.9633314609527588 - sq_loss: 1.2058549145876896e-06 - tot_loss: 0.7764776332255678 - acc: 0.8418166666666667 - val_acc: 0.8529\n",
      "Epoch 238 / 300 \n",
      " - time (s): 1.828256368637085 - sq_loss: 1.7077084066841053e-06 - tot_loss: 0.8108509722908366 - acc: 0.8386 - val_acc: 0.8483\n",
      "Epoch 239 / 300 \n",
      " - time (s): 1.7643375396728516 - sq_loss: 1.221104071191803e-06 - tot_loss: 0.8291793852041565 - acc: 0.8364666666666667 - val_acc: 0.8463\n",
      "Epoch 240 / 300 \n",
      " - time (s): 1.932758092880249 - sq_loss: 1.1038910088245757e-06 - tot_loss: 0.8919399611013432 - acc: 0.82875 - val_acc: 0.8416\n",
      "Epoch 241 / 300 \n",
      " - time (s): 1.8703124523162842 - sq_loss: 1.1835770692414371e-06 - tot_loss: 0.8065891309931885 - acc: 0.83085 - val_acc: 0.8416\n",
      "Epoch 242 / 300 \n",
      " - time (s): 1.77131986618042 - sq_loss: 1.4442989595409017e-06 - tot_loss: 0.804859195431618 - acc: 0.83155 - val_acc: 0.8466\n",
      "Epoch 243 / 300 \n",
      " - time (s): 1.8918061256408691 - sq_loss: 3.037759825019748e-06 - tot_loss: 0.7200159293363413 - acc: 0.8419 - val_acc: 0.8524\n",
      "Epoch 244 / 300 \n",
      " - time (s): 1.9182472229003906 - sq_loss: 2.6463389986020047e-06 - tot_loss: 0.8138765715943919 - acc: 0.8354 - val_acc: 0.845\n",
      "Epoch 245 / 300 \n",
      " - time (s): 1.7879419326782227 - sq_loss: 2.706905888771871e-06 - tot_loss: 0.8567542238183705 - acc: 0.8448 - val_acc: 0.853\n",
      "Epoch 246 / 300 \n",
      " - time (s): 1.747910737991333 - sq_loss: 2.01548959921638e-06 - tot_loss: 0.8975215024604495 - acc: 0.83205 - val_acc: 0.8433\n",
      "Epoch 247 / 300 \n",
      " - time (s): 1.7750024795532227 - sq_loss: 2.7194205358682666e-06 - tot_loss: 0.8541241459902267 - acc: 0.8484166666666667 - val_acc: 0.8568\n",
      "Epoch 248 / 300 \n",
      " - time (s): 1.8815510272979736 - sq_loss: 2.2412730231735623e-06 - tot_loss: 0.8060342592705183 - acc: 0.8373 - val_acc: 0.8467\n",
      "Epoch 249 / 300 \n",
      " - time (s): 1.803436040878296 - sq_loss: 1.2973274579053395e-06 - tot_loss: 0.842271884589195 - acc: 0.8335 - val_acc: 0.8456\n",
      "Epoch 250 / 300 \n",
      " - time (s): 1.8472378253936768 - sq_loss: 1.1579768397496082e-06 - tot_loss: 0.8950885125213972 - acc: 0.8458833333333333 - val_acc: 0.8551\n",
      "Epoch 251 / 300 \n",
      " - time (s): 1.8752880096435547 - sq_loss: 1.7274541050937842e-06 - tot_loss: 1.0457682551503922 - acc: 0.8454833333333334 - val_acc: 0.8545\n",
      "Epoch 252 / 300 \n",
      " - time (s): 1.8516738414764404 - sq_loss: 2.01516377273947e-06 - tot_loss: 0.9697158246835897 - acc: 0.8356333333333333 - val_acc: 0.8466\n",
      "Epoch 253 / 300 \n",
      " - time (s): 1.9235100746154785 - sq_loss: 2.206802037107991e-06 - tot_loss: 1.0978577910786953 - acc: 0.8467333333333333 - val_acc: 0.8597\n",
      "Epoch 254 / 300 \n",
      " - time (s): 1.8677635192871094 - sq_loss: 1.8164909079132485e-06 - tot_loss: 0.9447236677905266 - acc: 0.8427666666666667 - val_acc: 0.8529\n",
      "Epoch 255 / 300 \n",
      " - time (s): 1.8041701316833496 - sq_loss: 1.608522438800719e-06 - tot_loss: 0.9360496134878531 - acc: 0.8376333333333333 - val_acc: 0.8493\n",
      "Epoch 256 / 300 \n",
      " - time (s): 1.9181396961212158 - sq_loss: 1.5921523299766704e-06 - tot_loss: 0.9114154985745699 - acc: 0.8386166666666667 - val_acc: 0.8523\n",
      "Epoch 257 / 300 \n",
      " - time (s): 1.8511254787445068 - sq_loss: 2.536581405365723e-06 - tot_loss: 0.9493041990142501 - acc: 0.8402333333333334 - val_acc: 0.8506\n",
      "Epoch 258 / 300 \n",
      " - time (s): 1.8247401714324951 - sq_loss: 1.9180338313162792e-06 - tot_loss: 0.7722414929980914 - acc: 0.8483666666666667 - val_acc: 0.8588\n",
      "Epoch 259 / 300 \n",
      " - time (s): 1.7879207134246826 - sq_loss: 3.7138061088626273e-06 - tot_loss: 0.7309481908714588 - acc: 0.8458833333333333 - val_acc: 0.8545\n",
      "Epoch 260 / 300 \n",
      " - time (s): 1.761038064956665 - sq_loss: 2.9040616027486976e-06 - tot_loss: 0.7580501605548307 - acc: 0.8427 - val_acc: 0.8528\n",
      "Epoch 261 / 300 \n",
      " - time (s): 1.7407491207122803 - sq_loss: 4.9250979827775154e-06 - tot_loss: 0.8546289353384964 - acc: 0.84215 - val_acc: 0.8544\n",
      "Epoch 262 / 300 \n",
      " - time (s): 1.8601486682891846 - sq_loss: 3.297253897471819e-06 - tot_loss: 0.83567037262128 - acc: 0.8447833333333333 - val_acc: 0.8545\n",
      "Epoch 263 / 300 \n",
      " - time (s): 1.9502999782562256 - sq_loss: 1.364658714919642e-06 - tot_loss: 0.9200541573683267 - acc: 0.8442166666666666 - val_acc: 0.8531\n",
      "Epoch 264 / 300 \n",
      " - time (s): 1.8074893951416016 - sq_loss: 1.7640261376072885e-06 - tot_loss: 1.0262677423481819 - acc: 0.8401666666666666 - val_acc: 0.852\n",
      "Epoch 265 / 300 \n",
      " - time (s): 1.9522218704223633 - sq_loss: 4.201645424473099e-06 - tot_loss: 0.9036889757535391 - acc: 0.8467333333333333 - val_acc: 0.8538\n",
      "Epoch 266 / 300 \n",
      " - time (s): 1.9198291301727295 - sq_loss: 3.1467905046156375e-06 - tot_loss: 0.9415748981598426 - acc: 0.8341833333333334 - val_acc: 0.8468\n",
      "Epoch 267 / 300 \n",
      " - time (s): 1.828141212463379 - sq_loss: 1.012281131806958e-06 - tot_loss: 0.9838695505958412 - acc: 0.84505 - val_acc: 0.8556\n",
      "Epoch 268 / 300 \n",
      " - time (s): 2.0753021240234375 - sq_loss: 1.2314609421082423e-06 - tot_loss: 0.9079960451832676 - acc: 0.85005 - val_acc: 0.8599\n",
      "Epoch 269 / 300 \n",
      " - time (s): 1.8445711135864258 - sq_loss: 1.2161042377556441e-06 - tot_loss: 0.9371784623697295 - acc: 0.8353666666666667 - val_acc: 0.8463\n",
      "Epoch 270 / 300 \n",
      " - time (s): 1.8605051040649414 - sq_loss: 1.1227855338802328e-06 - tot_loss: 1.0763606671087018 - acc: 0.84635 - val_acc: 0.8563\n",
      "Epoch 271 / 300 \n",
      " - time (s): 1.8993024826049805 - sq_loss: 1.4855025938231847e-06 - tot_loss: 0.8982688217623718 - acc: 0.8397166666666667 - val_acc: 0.8516\n",
      "Epoch 272 / 300 \n",
      " - time (s): 1.8960449695587158 - sq_loss: 1.5947123301884858e-06 - tot_loss: 0.9992221591980979 - acc: 0.8489833333333333 - val_acc: 0.858\n",
      "Epoch 273 / 300 \n",
      " - time (s): 1.817674160003662 - sq_loss: 1.5371671224784222e-06 - tot_loss: 0.8977537738911678 - acc: 0.8503666666666667 - val_acc: 0.8588\n",
      "Epoch 274 / 300 \n",
      " - time (s): 1.947416067123413 - sq_loss: 1.5762794873808161e-06 - tot_loss: 0.7947851313680303 - acc: 0.8416333333333333 - val_acc: 0.8521\n",
      "Epoch 275 / 300 \n",
      " - time (s): 1.7975242137908936 - sq_loss: 1.4656855000794167e-06 - tot_loss: 0.8743641591584037 - acc: 0.8455833333333334 - val_acc: 0.8558\n",
      "Epoch 276 / 300 \n",
      " - time (s): 1.759861707687378 - sq_loss: 1.3299824104251456e-06 - tot_loss: 0.9965333634164608 - acc: 0.8468333333333333 - val_acc: 0.8579\n",
      "Epoch 277 / 300 \n",
      " - time (s): 1.7728843688964844 - sq_loss: 1.3437415873340797e-06 - tot_loss: 0.918726440642331 - acc: 0.8479833333333333 - val_acc: 0.8582\n",
      "Epoch 278 / 300 \n",
      " - time (s): 1.7845008373260498 - sq_loss: 1.406380192747747e-06 - tot_loss: 1.2522369577330892 - acc: 0.8426 - val_acc: 0.8542\n",
      "Epoch 279 / 300 \n",
      " - time (s): 1.8736844062805176 - sq_loss: 1.2302507457206957e-06 - tot_loss: 0.9596480514073846 - acc: 0.8491666666666666 - val_acc: 0.8599\n",
      "Epoch 280 / 300 \n",
      " - time (s): 1.9024507999420166 - sq_loss: 1.1047167163269478e-06 - tot_loss: 0.8260247342349203 - acc: 0.83985 - val_acc: 0.8518\n",
      "Epoch 281 / 300 \n",
      " - time (s): 1.9748353958129883 - sq_loss: 1.1468712273199344e-06 - tot_loss: 0.9260614522829655 - acc: 0.8463333333333334 - val_acc: 0.8551\n",
      "Epoch 282 / 300 \n",
      " - time (s): 1.9525654315948486 - sq_loss: 1.119859803111467e-06 - tot_loss: 0.8743969728274124 - acc: 0.8475666666666667 - val_acc: 0.8599\n",
      "Epoch 283 / 300 \n",
      " - time (s): 1.8982198238372803 - sq_loss: 1.6937799500738038e-06 - tot_loss: 0.8883858600299845 - acc: 0.8500833333333333 - val_acc: 0.8593\n",
      "Epoch 284 / 300 \n",
      " - time (s): 1.7380757331848145 - sq_loss: 1.6097289972094586e-06 - tot_loss: 0.8851944053019452 - acc: 0.8451666666666666 - val_acc: 0.8579\n",
      "Epoch 285 / 300 \n",
      " - time (s): 1.7811360359191895 - sq_loss: 1.5651322655685362e-06 - tot_loss: 0.8100704156451002 - acc: 0.8490166666666666 - val_acc: 0.8614\n",
      "Epoch 286 / 300 \n",
      " - time (s): 1.900564193725586 - sq_loss: 1.5287648693629308e-06 - tot_loss: 0.9061637021065962 - acc: 0.8456833333333333 - val_acc: 0.8542\n",
      "Epoch 287 / 300 \n",
      " - time (s): 1.742609977722168 - sq_loss: 1.7203901734319516e-06 - tot_loss: 1.0102298941119443 - acc: 0.8521166666666666 - val_acc: 0.8622\n",
      "Epoch 288 / 300 \n",
      " - time (s): 2.022277355194092 - sq_loss: 1.2466929319998599e-06 - tot_loss: 0.8536316646599289 - acc: 0.8466666666666667 - val_acc: 0.8578\n",
      "Epoch 289 / 300 \n",
      " - time (s): 1.7938966751098633 - sq_loss: 1.3082252507956582e-06 - tot_loss: 0.8415816272162147 - acc: 0.8451666666666666 - val_acc: 0.8553\n",
      "Epoch 290 / 300 \n",
      " - time (s): 1.7828526496887207 - sq_loss: 1.7406152892363025e-06 - tot_loss: 0.8401297731240902 - acc: 0.8490666666666666 - val_acc: 0.8611\n",
      "Epoch 291 / 300 \n",
      " - time (s): 1.9702694416046143 - sq_loss: 1.7157028651126893e-06 - tot_loss: 0.8851637697837305 - acc: 0.8513166666666667 - val_acc: 0.8628\n",
      "Epoch 292 / 300 \n",
      " - time (s): 1.7631077766418457 - sq_loss: 1.1181172112628701e-06 - tot_loss: 0.828027933503904 - acc: 0.8483166666666667 - val_acc: 0.8596\n",
      "Epoch 293 / 300 \n",
      " - time (s): 1.8697171211242676 - sq_loss: 1.734777697492973e-06 - tot_loss: 0.9047036287304309 - acc: 0.8480333333333333 - val_acc: 0.8582\n",
      "Epoch 294 / 300 \n",
      " - time (s): 1.8419625759124756 - sq_loss: 1.1950168072871747e-06 - tot_loss: 1.0936284909392953 - acc: 0.8527666666666667 - val_acc: 0.8615\n",
      "Epoch 295 / 300 \n",
      " - time (s): 1.7575678825378418 - sq_loss: 1.8133921457774704e-06 - tot_loss: 0.8799109325589143 - acc: 0.8508166666666667 - val_acc: 0.8617\n",
      "Epoch 296 / 300 \n",
      " - time (s): 1.8226523399353027 - sq_loss: 2.4367079731746344e-06 - tot_loss: 0.9532987117388529 - acc: 0.8405166666666667 - val_acc: 0.8528\n",
      "Epoch 297 / 300 \n",
      " - time (s): 1.9086418151855469 - sq_loss: 1.784896312528872e-06 - tot_loss: 0.9941768453193163 - acc: 0.85315 - val_acc: 0.8648\n",
      "Epoch 298 / 300 \n",
      " - time (s): 1.7748610973358154 - sq_loss: 3.1952188237482915e-06 - tot_loss: 0.8971550767257668 - acc: 0.8509166666666667 - val_acc: 0.8609\n",
      "Epoch 299 / 300 \n",
      " - time (s): 1.9286155700683594 - sq_loss: 2.2088577225076733e-06 - tot_loss: 0.829926644176112 - acc: 0.84655 - val_acc: 0.8564\n",
      "Epoch 300 / 300 \n",
      " - time (s): 1.954129934310913 - sq_loss: 1.410310460414621e-06 - tot_loss: 0.8770350858146685 - acc: 0.84875 - val_acc: 0.8611\n"
     ]
    }
   ],
   "source": [
    "# Iterations\n",
    "print('Train on', N, 'samples, validate on', N_test, 'samples')\n",
    "for k in range(niter):\n",
    "    start = time.time()\n",
    "    '''\n",
    "    # update V4\n",
    "    V4 = (y_one_hot + gamma*U4 + alpha*V4)/(1 + gamma + alpha)\n",
    "    \n",
    "    # update U4 \n",
    "    U4 = (gamma*V4 + rho*(torch.mm(W4,V3) + b4.repeat(1,N)))/(gamma + rho)\n",
    "    '''\n",
    "    # update V11\n",
    "    V11 = (y_one_hot + gamma*U11 + alpha*V11)/(1 + gamma + alpha)\n",
    "    \n",
    "    # update U11\n",
    "    U11 = (gamma*V11 + rho*(torch.mm(W11, V10) + b11.repeat(1,N)))/(gamma + rho)\n",
    "    \n",
    "    # update W11, b11, V10 and U10\n",
    "    W11, b11, V10, U10 = block_update(W11, b11, W10, b10, V11, U11, V10, U10, V9, d10)\n",
    "    \n",
    "    # update W10, b10, V9 and U9\n",
    "    W10, b10, V9, U9 = block_update(W10, b10, W9, b9, V10, U10, V9, U9, V8, d9)\n",
    "    \n",
    "    # update W9, b9, V8 and U8\n",
    "    W9, b9, V8, U8 = block_update(W9, b9, W8, b8, V9, U9, V8, U8, V7, d8)\n",
    "    \n",
    "    # update W8, b8, V7 and U7\n",
    "    W8, b8, V7, U7 = block_update(W8, b8, W7, b7, V8, U8, V7, U7, V6, d7)\n",
    "    \n",
    "    # update W7, b7, V6 and U6\n",
    "    W7, b7, V6, U6 = block_update(W7, b7, W6, b6, V7, U7, V6, U6, V5, d6)\n",
    "    \n",
    "    # update W6, b6, V5 and U5\n",
    "    W6, b6, V5, U5 = block_update(W6, b6, W5, b5, V6, U6, V5, U5, V4, d5)\n",
    "    \n",
    "    # update W5, b5, V4 and U4\n",
    "    W5, b5, V4, U4 = block_update(W5, b5, W4, b4, V5, U5, V4, U4, V3, d4)\n",
    "    \n",
    "    # update W4, b4, V3 and U3\n",
    "    W4, b4, V3, U3 = block_update(W4, b4, W3, b3, V4, U4, V3, U3, V2, d3)\n",
    "    \n",
    "    # update W3, b3, V2 and U2\n",
    "    W3, b3, V2, U2 = block_update(W3, b3, W2, b2, V3, U3, V2, U2, V1, d2)\n",
    "    \n",
    "    # update W2, b2, V1 and U1\n",
    "    W2, b2, V1, U1 = block_update(W2, b2, W1, b1, V2, U2, V1, U1, x_train, d1)\n",
    "    \n",
    "    # update W1 and b1\n",
    "    W1, b1 = updateWb_js(U1, x_train, W1, b1, alpha, rho)\n",
    "\n",
    "    # compute updated training activations\n",
    "    _, a1_train = feed_forward(W1, b1, x_train)\n",
    "    _, a2_train = feed_forward(W2, b2, a1_train)\n",
    "    _, a3_train = feed_forward(W3, b3, a2_train)\n",
    "    _, a4_train = feed_forward(W4, b4, a3_train)\n",
    "    _, a5_train = feed_forward(W5, b5, a4_train)\n",
    "    _, a6_train = feed_forward(W6, b6, a5_train)\n",
    "    _, a7_train = feed_forward(W7, b7, a6_train)\n",
    "    _, a8_train = feed_forward(W8, b8, a7_train)\n",
    "    _, a9_train = feed_forward(W9, b9, a8_train)\n",
    "    _, a10_train = feed_forward(W10, b10, a9_train)\n",
    "    \n",
    "    \n",
    "    # training prediction\n",
    "    pred = torch.argmax(torch.addmm(b11.repeat(1, N), W11, a10_train), dim=0)\n",
    "    # pred = torch.argmax(torch.addmm(b4.repeat(1, N), W4, a3_train), dim=0)\n",
    "    \n",
    "    # compute test activations\n",
    "    _, a1_test = feed_forward(W1, b1, x_test, N_test)\n",
    "    _, a2_test = feed_forward(W2, b2, a1_test, N_test)\n",
    "    _, a3_test = feed_forward(W3, b3, a2_test, N_test)\n",
    "    _, a4_test = feed_forward(W4, b4, a3_test, N_test)\n",
    "    _, a5_test = feed_forward(W5, b5, a4_test, N_test)\n",
    "    _, a6_test = feed_forward(W6, b6, a5_test, N_test)\n",
    "    _, a7_test = feed_forward(W7, b7, a6_test, N_test)\n",
    "    _, a8_test = feed_forward(W8, b8, a7_test, N_test)\n",
    "    _, a9_test = feed_forward(W9, b9, a8_test, N_test)\n",
    "    _, a10_test = feed_forward(W10, b10, a9_test, N_test)\n",
    "    \n",
    "    # test/validation prediction\n",
    "    pred_test = torch.argmax(torch.addmm(b11.repeat(1, N_test), W11, a10_test), dim=0)\n",
    "    # pred_test = torch.argmax(torch.addmm(b4.repeat(1, N_test), W4, a3_test), dim=0)\n",
    "    \n",
    "    # compute training loss\n",
    "    loss1[k] = gamma/2*torch.pow(torch.dist(V11,y_one_hot,2),2).cpu().numpy()\n",
    "    # loss1[k] = gamma/2*torch.pow(torch.dist(V4,y_one_hot,2),2).cpu().numpy()\n",
    "    loss2[k] = loss1[k] \\\n",
    "    + compute_loss(W1, b1, x_train, U1) \\\n",
    "    + compute_loss(W2, b2, V1, U2) \\\n",
    "    + compute_loss(W3, b3, V2, U3) \\\n",
    "    + compute_loss(W4, b4, V3, U4) \\\n",
    "    + compute_loss(W5, b5, V4, U5) \\\n",
    "    + compute_loss(W6, b6, V5, U6) \\\n",
    "    + compute_loss(W7, b7, V6, U7) \\\n",
    "    + compute_loss(W8, b8, V7, U8) \\\n",
    "    + compute_loss(W9, b9, V8, U9) \\\n",
    "    + compute_loss(W10, b10, V9, U10) \\\n",
    "    + compute_loss(W11, b11, V10, U11) \n",
    "    \n",
    "    # compute training accuracy\n",
    "    correct_train = pred == y_train\n",
    "    accuracy_train[k] = np.mean(correct_train.cpu().numpy())\n",
    "    \n",
    "    # compute validation accuracy\n",
    "    correct_test = pred_test == y_test\n",
    "    accuracy_test[k] = np.mean(correct_test.cpu().numpy())\n",
    "    \n",
    "    # compute training time\n",
    "    stop = time.time()\n",
    "    duration = stop - start\n",
    "    time1[k] = duration\n",
    "    \n",
    "    # print results\n",
    "    print('Epoch', k + 1, '/', niter, '\\n', \n",
    "          '-', 'time (s):', time1[k], '-', 'sq_loss:', loss1[k], '-', 'tot_loss:', loss2[k], \n",
    "          '-', 'acc:', accuracy_train[k], '-', 'val_acc:', accuracy_test[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'validation accuracy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8XHW5+PHPMzOZyZ40S7ckXWkLLW1ZQivILkvLql6Qwo8rqNiLiorL9YIXUVGvXjfUK/cqICgoFuQi9kKVHVkspS0tdKNtuqdb0qTZl9m+vz/OOZMzk0kzbSdNJn3er1dembPM5Hsy7TNPnu9yxBiDUkqp4cUz2A1QSimVfhrclVJqGNLgrpRSw5AGd6WUGoY0uCul1DCkwV0ppYYhDe7qmBCR80Wk1rW9TkTOT+XcI/hZvxKRbxzp85UaDnyD3QB1fDLGzEjH64jIzcAtxpizXa99azpeW6lMppm7UhlCRDQZUynT4K5SJiJ3iMiTCft+LiK/sB9/QkQ2iEiriGwVkX85xGttF5GL7Mc5IvJbETkoIuuBM5L83C32664XkY/Y+08CfgWcKSJtItJk7/+tiHzX9fxPi0iNiDSKyGIRGes6ZkTkVhHZbP/8+0RE+mjzHBFZKiJNIrJXRH4pIn7X8Rki8oL9c/aLyNft/V4R+brrGlaKSJWITLB/vs/1Gq+KyC3245tF5E0RuVdEGoFvichkEXlZRBpE5ICI/EFEil3PrxKRp0Sk3j7nlyISsNs003XeSBHpFJHyvt4jldk0uKvD8UfgMhEpBCtoAR8DHrOP1wFXAIXAJ4B7ReS0FF73m8Bk++tS4KaE41uAc4Ai4NvA70VkjDFmA3ArsNQYk2+MKU54HiJyIfB9u51jgB3AooTTrsD6QJltn3dpH+2MAF8CyoAzgQ8Bn7V/TgHwIvA3YCxwAvCS/bwvA9cDl2H9bj4JdBzqF+IyF9gKjAS+B4h9PWOBk4Aq4Ft2G7zAM/Y1TgAqgEXGmG77mm90ve71wIvGmPoU26EyjTFGv/Qr5S/gDeDj9uOLgS2HOPdp4Iv24/OBWtex7cBF9uOtwDzXsYXuc5O87mrgavvxzcAbCcd/C3zXfvwb4IeuY/lACJhgbxvgbNfxJ4A7Uvxd3A782X58PbCqj/M2Ou1N2D/B/vk+175XsfoQnGvb2U8bPuz8XKwPnHr367nOmwvsAjz29grgY4P970m/Bu5LM3d1uB7DCmQAN9CTtSMi80XkLbsE0ISVqZal8JpjsQKPY4f7oIh8XERW2+WQJuDkFF/Xee3Y6xlj2oAGrKzWsc/1uAPrA6AXEZkqIs+IyD4RaQH+w9WOKqy/MJI51LH+uH8vTjllkYjsttvw+4Q27DDGhBNfxBizDGgHzhORE7H+slh8hG1SGUCDuzpcfwLOF5FK4CPYwV1EAsD/Aj8GRhmrRLIEq4zQn71YgckxznkgIuOBB4DbgFL7dde6Xre/ZU33AONdr5cHlAK7U2hXov8B3gemGGMKga+72rELq6yUTF/H2u3vua59oxPOSby+79v7ZtltuDGhDeMO0fH6O/v8fwaeNMZ09XGeGgY0uKvDYqwa7avAw8A2Y9W9AfxAAKssEBaR+cAlKb7sE8CdIjLC/tD4vOtYHlYwqwer0xYrc3fsByrdHZsJHgM+ISKn2B9A/wEsM8ZsT7FtbgVAC9BmZ7+fcR17BhgtIrfbHZgFIjLXPvYg8B0RmSKWWSJSav8udwM32p2un6TvDwh3G9qAJhGpAP7VdextrA/KH4hInohki8gHXccfxfpAvhF45AiuX2UQDe7qSDwGXISrJGOMaQW+gBWoD2KVbFL9s//bWKWTbcDzWEHIed31wE+ApViBfCbwpuu5LwPrgH0iciDxhY0xLwHfwPqrYi9W8FyQYrsSfRXrulqx/pp43PVzWrH6IK7EKvNsBi6wD/8U6/fyPNaHw2+AHPvYp7ECdAMwA/hHP234NnAa0Aw8CzzlakPE/vknADuBWuA61/Fa4B2sD8vXD+O6VQYSY/RmHUodL0TkIWCPMeauwW6LGlg6KUKp44SITAA+Cpw6uC1Rx4KWZZQ6DojId7A6on9kjNk22O1RAy+lsoyIzAN+DniBB40xP0g4Ph54CCgHGoEb7fqeUkqpQdBvcLdnvW3C6iyqBZYD19sdXc45fwKeMcb8zp4R+AljzD8PXLOVUkodSio19zlAjTFmK4CILAKuBta7zpmONS0b4BWsmYmHVFZWZiZMmHBYjVVKqePdypUrDxhj+l0TKJXgXkH8LLlarKnMbu8C/4RVuvkIUGCP421wnyQiC7GmljNu3DhWrFiRwo9XSinlEJEd/Z+VWodqshmGibWcr2JNa14FnIc1MSPZFOj7jTHVxpjq8nJdjE4ppQZKKpl7LfFTwyuxpnTHGGP2YA2xQkTygX8yxjSnq5FKKaUOTyqZ+3JgiohMtKd4LyBh5qGIlImI81p3Yo2cUUopNUj6De72CnO3Ac8BG4AnjDHrROQeEbnKPu18YKOIbAJGYa07rZRSapAM2vID1dXVRjtUlVLq8IjISmNMdX/n6QxVpZQahjS4K6XUMKTBXSmlBlA0anh61W4a24PH9OdqcFdKZZTG9iDBcPSIntsZjKQcZCNRw/4W62ZV0ahhw94WmjqCbN7fyr0vbOK92iZufvhttta30dIV4stPrObUe57nsWU72d3UydeefJdbH13J4yt2cfvjq/l/Dy6joa2bO59aw9b6tiNq/+HQDlWl1JD04vr9VE8YQXGuH2MMIkIoEuXM77/E2SeU8bMF1srFxhgWPrqSsnw/3/vwTDye5Hd2rG/t5qwfvMTIgmyWfPEcWjpDrNndzI+f30hRThaPfHIOjy/fxfPr9lNW4EdEeGH9fl780nnc++Im/rxqNyIQ8HnoCkUpyPbR2hWmckQOU0cV8NqmeqaNLmDdnha8HsHv9RCOWh9CXo8QjUJ2loeWrjA/vnY215xeeUS/l1Q7VHU9d6XUgIhGDev2tHByRSEiVsCNRA0vbtjPeVPLyc7yxp2/cV8rJ4zM55n39jChNI9bHlnBDXPHcfcV07n0Z6/R3h3mspljONAW5OnVe1gwZxxVJbm8taWBF9bvB2BPUxc+j7D1QDsVxTlcMmMUDW1BxhRl88L6/YQiht1NnVz7q3+ws7EDn8dDSZ6fVTubOP9Hr9LQHmRmRREvrq8jGLEC8/UPvMXupk5uPmsChdk+djZ2sKe5i7e3NfLhU8byRk0DL79fx5cumsptF57A06t2887Og9x01gR+8/o2Hl+xi/knj+GymWO47bF3uPW8yUcc2A+HZu5KKQDqWrroCEaYUJZ3xK8RikTJ8lrV3v95dQv/+bf3uWP+iXSHonzi7An8be0+vvbke1w6YxT33XAaPvvcv67Zy2f+8A5zJ5awbFsjpXl+GtqDFAR8fG3eNL7xl3WMKgywv6Ubv8/DyIIATR0hOkMRIlHDmKJsPn7mBO5/bQt+n4fqCSVs2NvC1nrrHuRejxCJGhacUcWi5dZSWSLg93p4/kvn8r1nN/Dqxnp+et1srpg1ltc31/PK+/V0hSM8tmwnnzp7InddflLsQ2r7gXb++9Ua7r5yBpGI4bXN9cw/eXTsehw1da1c+V9vcv/HT+ecKeW0doUoyM464t+v1e7UMncN7koNU04pw62utQu/18Nz6/aR4/dx1eyxsWPX3/8We5s7efVfL0h8KfY0dbK3uZP1e1p48I1tfPiUCjbua+XuK6ezu6mTcMSwYnsjv3ylhruumM6Vs8Zwzg9fobWrZ4mpS6aPYndTJzsaOmjrDjO+NJdf//PpFOf4uewXr3OwI4g7HOX6vXQEIwR8HqpKcvn2VTP4fw8u44Jp5dxz9cnc+vuVTCzLY2JZHnMmlnDOlHKiUesFnNLMlvo22rrC3PjgMkLRKEvv+BDX3b+Umro2/vczZ+H3eZgxtoiuUISG9iAVxTlx190VirBxXyuzq4qP+H2IRA3ePkpFR0LLMkodB17fXM+MsUWU5Pl7HVtw/1uMLMzm7iumU5ybhVeE6379Fi2dIRo7gowtymFSWR6Llu9kTFEOb21rwBjY19zF6KJslm1tYN2eFiaW5XHbY+/QGYqQ5/fR2h3m5y9tRgT+tm5f3M8sLwjwjafX8u6uJlrt2vLjy3cydVQBf1i2E4DvfvhkxhRlc+dTa/jkw8spyvXTFYrwm5uq+fxjq7hy9lgWLd/FDXPGkeXz8Le1+/j8hSdw1uRSvnLxVM46oZSqklye/cI5va45sd4+uTwfgJ8tOIW27jAj8vx84UNT2H6gnVPHjYidl53l7RXYnf1HE9iBtAb2w6GZu1LH2Kb9rdz19Foe+Hg1IlB4mH+md4cj3PzQcm78wHhu++M7LDx3EmOLcpg7qYTvPrOB+TNHc9bkMi748aux51w+aww3zh3P9Q+8FQs2kaihMNtHRzBCONoTB26YO45TKot58p1a3t7WSJ7fS1VJLq1dYXY3dfKrG0/H5xEKc7L486rdXHjiSEKRKJv2t3LDnHGc9YOXCUcN00YV8NyXzgWsvyJW7jjI1gPtfOTUCrK8HtbUNnPr71fSGYrwHx+ZybyTRxMMR8nyCn9aWcv508oZWZB99L/wYUYzd6WGqP97dw9vb2vkv17azMP/2M5zt5/LCSPzU37+qp1NLN3awP6WLoyBlzbUUVPXxomjC3h/Xyv1rd2E7KGCd11+Eiu2H+TZ9/ZSe7CTgoCPv95+Do3tQa765Zu0dIW597rZPPPuXoKRKK9vPsBjy3by+PJdOIlfZyjCj6+djc8rrNrZxLyTR8faMmdiSezxZTPHAPDBE8r4+6b6uPNEhOoJJVRP6Dl/ZmURb95xYdy1+X1Wzfpj1VWoo6PBXakBdKCtm7+s3sPHqitjHWlvb2sE4PfLdhCJGt7YXM+ybQ0UZmdRVZLL+JJcRODmh5ezvaGdC08cSWF2Fp86eyJVJbm8WXMAgK0HrM7CmjprzPT7+1oB2Li/lQde38bEsjxuOWcS11aHeHPLAd7d1cSXLppK5YhcKkfkMq4klzZ7BMpHTq0kGjWc9t0XaOoIYYwhauC+G06jKCeLkyuKADhxdGG/1/yRUyt4fXM9l88ak95fpjosWpZR6ijVt3azs7GD08eP6HXsFy9t5qcvbKJyRA4P3lTN/X/fylOrdsedU5ybRVNHKLbt93q4fNYY/rxqN/NmjObljXWEIlFmVRRx3tRyfvFyTZ9tKcsPcKCtG4AvXHgCX75kGgBrdzcjAjPGFsXOfW1TPVFjOH/ayNi+tbub2dfcxdOrd7NqZxOvf+2CPseN98UYw57mrqQ1bHX0dLSMUmlw51NreH7dPq6cPZZvXjm91+gTgK888S7/994e3vvmJb3Gbn/hj6tY/K51bxtnmB9ASZ4/bqbkmKJsHv7EGdQ2dnLHU2s40NbN+NJcXv3q+RgDz67Zy+f/uCp2/pSR+Wyua2NMUTZ7m7uYM7GE9XtauO6MKkYWBBiR6+ea0ysPOzA7OoMROoJhSvMDR/R8NXC05q5UEku3NDC+NJeCbB8Bnxe/z5N0yCBYWewf397JpPI8fvuP7Zw2fkTc0EGwJuq8urGOYDjKqp1NnDm5NO54TV0bMyuKWLO7ORbYL5hWzuyqYn724uZYnfzSGaM5cXQhJ44u5IbaJn7xcg3zZoxGRBCBK2ePZWRBgMqSXJZuaWDG2ELm//x1Lp85hr9vquea0yo589pSSvP95PqP/r91jt9Ljt/b/4lqyNLgroYdZ8RFYsA2xnD9A28BUFGcwwUnlnPX5dO57tdLKczJ4rsfPpmK4hx8Xg/RqOE7z6ynODeLpz5zFjc9vJxv/mUtZ00upcyVza7d00yDnYG/va2RMyeX8pfVu/nW4nX89LpT2FLfxsfPHE9je9CaGXl6JT+6dja7mzrZWt/OFbPGsPDRlVw5u6c+feOZ41mx4yDXnRHfqTh3kvXB4cxu/MFHZ3LO1HLuumJ6+n+JKuPpwmFqWOkKRZh611/5+Uubex1rcU2o2d3UyTPv7eU7z6zn3dpmlm5p4Lwfvcrtj68G4KE3t7FsWyNfn38Sxbl+fnTNLNq7I3z9qTU0tHXzXm0ToUiUFzfUIQKVI3J4e3sDAEvW7OVgR4hPPLyc7nCUE0bmM6vSqnWfMs4aM11RnMMvrj+VS2aM5vWvXcDp43tGkYwsyOaxT3+ASeWHHkGzYM44rWurPqUU3EVknohsFJEaEbkjyfFxIvKKiKwSkfdE5LL0N1Wp/u1rtlbx+9mLVnD/y+rd1B7siDsG4BFo6gjxh2U7+eQHJ/L05z7I+dPKeWlDHXWtXfz8pc2cP62ca6utLHnqqAK+Nm8az6/fz5nff5mrfvkml977Go8s3c55U8u5ePooVmw/SGtXiI37WjltXM/ElxNG5scmwpySZEJMVUnugPwu1PGt3+AuIl7gPmA+MB24XkQS/w68C+veqqdi3UD7v9PdUHV86wpF+N0/ttPcGYrbv3Z3MxHXBJy61u7Y48b2IF9ctDo2M3JvcycAowoD3Dn/JAI+D2OKsvnKJVM5uaKIm86aQGcowi2/W0FrV5h/vXRaXGnnU2dP5F/Om8QZE0fw/Y/OZE9zJ00dIb588VSumj2W7nCUP769k+0NHVx44sjYUMATRhZw/Rnj+OE1s5g+pv+hhEqlQyo19zlAjTFmK4CILAKuBta7zjGA86+2CNiTzkaq40M0ath1sIPxpb0Xrvrzqt18c/E6XttUzwMfr8bjEdbtaeaK/3qDn113CrMqi5hQmke9K7g/9U4tQGxNbidzf+qzH6SiOIeqkhzGFueQF7D+G5xp17Tfq23millj4oYNgjUR5875J8W2J5fnU1PXxqzKYowxTB2Vz38seR+AkyuK+Mz5J3DHvBMpyrHGt+vEHHUspRLcK4Bdru1aYG7COd8CnheRzwN5wEXJXkhEFgILAcaNG3e4bVXD3CNLt/Ot/1vPM58/OzZpxvGX1bvxez289H4df127j9/+YxvFudZ6Kn9bu4/bH1/NgjOqmDa6IPYcZ/U/J+Dvbe5CBEYWWB2i806On2STneXlKxdPpbkzxNfmndhve+dMLInN0BQRbj1vMl9+4l0AZlYU4fWIllzUoEkluCcbKJs4OP564LfGmJ+IyJnAoyJysjEm7nYpxpj7gfvBGud+JA1Ww9fG/dYMy2XbGuOCe01dK8u2NXLj3PE8+tYO/rRyF8u3H4wdf2GDtZb3ouW7+OhpFfg8wsSyPDbbMzfrWqzgvq+5i/L8QGxJ2mQ+/6EpR9z+j55WybiSXLYeaNfx4WrQpdKhWgu4/56spHfZ5VPAEwDGmKVANlCWjgaq44czxHBHQzuhSJRXNtax/UA7C+5/i+KcLG49fzK5fm9s+j5YszndNfc/r9pNWX4gruNyf2sXB+2hiGOKBnYhquoJJVp+UUNCKsF9OTBFRCaKiB+rw3Rxwjk7gQ8BiMhJWMG9Pp0NVZktHInS1h2m9mAHT66sje13B2Zn7e91e1p4etVuPvHwci752Wt0h6L86dazqCjOYVxJLh3BCH6fh29fNYPPXjAZsEokVSU5GAMjCwNxy7Q2dYQ4+z9f5o2aA4xIsjSuUsNRv2UZY0xYRG4DngO8wEPGmHUicg+wwhizGPgK8ICIfAmrZHOzGax1DdSQ9Nt/bOfXr22lojiH1buaOGeKtXLg957dwJ8/exYb97XGRsKs29PMq5usDDsYjvKNy0+KrZpYVZLL+/tamVyez01nTeAf9iJap1YVU14QYFdjJ+WuzN3v8xAMR2kPRgAYpUvIquNESjNUjTFLgCUJ++52PV4PfDC9TVPDibMUrXOnnHd2HORXf99Cc2eIC3/ydwCmjbI6Q7tCUZ5bu4+rZo/lprPGc5rrpgrj7Q7KCaXW95mVRcyuKmb+zDG8va2BZ9/by8jCANNGFzC5PI+ZFUU8vdqqIv7gozO5aPqoY3bNSg0mXX5AHRPOcMSI/Qfdf71cw9b69ti9MgFq6tuYO7GE5s4Q7+9r5YITy+NmbgKMs4O6M1yyIDuLv3zOyis67ezc6TR96Svns3Z3M0+v3kOu38u11VWDdlccpY41XX5AHZXucISuUKTf85wRK87Stuv3tjCmKJtHPjWHufZwwkjUUFYQ4GcLTuGik0Zx4Ym9s+xxduY+saz3EMNZlUVUleTEpvhDz7DHGWMLNbCr44oGd3VUvv7UWm75Xf9LN+9v7eq172vzpjFjbBG/uvH02L7inCxOHF3IgzdVxyb/uJ02fgSXzhjFuVPLex3LC/h4/WsXxn0olOYHCPg8zK48uvtgKpVptCyjjsq6Pc3sbuokGI4SNabXeuZgLR3gvhnFVbPHMm10AVfPrgCsm1X4vR6CkWjSgO5WmJ3Fr/+536WsY7we4fF/OTNWo1fqeKHBXR3Sg69vZcmavVxbXcX1c3pmFf9pxS7CUcOuxg7agxE+/8d3ONge4olbz+z1Gk5JxvGBSaXcMLfntUSEkYUBag92Upx7eDeLTkWyxbqUGu40uKtDevD1bexr6SLH740L7r95w9rvDDF8Yf1+ChOybucmGIklGacO7jaqMJvag539Zu5KqdRocFd9ikZN7H6c7uw7GjVsO9BOd7hndYmosTpLmztCvLBhPw+/uY3ucJRnPn92bKSMc0u4kYXJgru1ryhHJxkplQ4a3FWfmjpDhO1x6fVtPcF9b0tXXGB3+8KiVfx9Uz1ji7LZ09zFo0t3xO7jObOiyAruSSYSjSq09g1EWUap45GOllF9clZTPHF0AU0dIbrDVglmW3173HkjXAH57W2NnD5+BG/824WcM6WM7y3ZwA/+uoH8gI/ZVcXk+r2U5vfOzp3grmUZpdJDM3fVJye4Tx9TGJthWjkil20HrNUWs7xCrt/HyRVFvFFzAGOgMxRhYlkeHo/wX9efyqLlu2hsD/LhUyqYWJbHZTPHJF2VcXZlMWX5ASpG6G3jlEoHDe6ql7+t3cv40jzq26xa+YyKIp5atZs6O7hvPdBOrt/L7MpiOkIR7px/EpvrWvniIuv+o85Eo+JcP7eeNznutSeW9b4RB8CZk0tZcVfS2wAopY6AlmWGkcb2IB++7012NnQc1et8/c9reeD1rbFO1BljrZtsOZn8lvp2JpTm8cNrZnHvx2YzfWwhl80cg3NHunF6gwqlBp0G92Fk475WVu9q4t3apiN+jWjU0NQR5GB7kPrWbnKyvLFsu661m65QhOV2Xb2qJJdJ5dZqjVleDyX2nZH07kNKDT4N7sNIS1co7vuRaAuGiRpo7AhR39ZNeUGA0jw/IlDf0sU/thygMxTh4iSrK5bb49c1c1dq8GnNfRhx1kN3bnpxRK9hLxNwsD1Int9LeUEAn52V/2HZTlbuPEh+wMfcSSW9nlteEGBHQwdlSUbDKKWOLc3cM1xXKMKPn9tIVyhCix3cne9HwvmAcMoyTqCeWJZHQ3uQf2xp4KazxhPw9V5DZs6EEs6dWoaIrr6o1GBLKXMXkXnAz7HuxPSgMeYHCcfvBS6wN3OBkcYYXdDjGFix/SC/fKWGsyaXxgLz4ZZljDF8/KG3aeoIcc4U69a3rd1hQgc7+OAJ1vaDN1Wzr6WLiuIcCrKTj0U/mptLK6XSq9/gLiJe4D7gYqybZS8XkcX23ZcAMMZ8yXX+54FTB6CtKglnYlF3OOrK3HvKMvWt3Xz2Dyv54oemcvaU3vcs/9wf3mFGRSGvb7ZuV7ftQM8Epa5QlEp73Hlxrp/iXC23KJUpUinLzAFqjDFbjTFBYBFw9SHOvx74Yzoap/oXtJcB6A5HXDX3nsz9ly9vZvn2g/z702tiHwSO7nCEZ9fs5Yd/2whAYbaPtu74en1FsU4qUioTpRLcK4Bdru1ae18vIjIemAi8fPRNU6kIRpzgHnWVZawAfbA9yGNv72RWZRE7Gjp45t29cc91d7yW5QeSZvaVI3Tki1KZKJXgnqx3zPRx7gLgSWNM0vuuichCEVkhIivq6+tTbaM6BGcBr+5QNBbUnfLM/tYuQhHDp8+ZhN/rYVNda9xz3cF97qQSxhT1ztJ1OQClMlMqwb0WqHJtVwJ7+jh3AYcoyRhj7jfGVBtjqsvLe98mTR2+ZGUZp0O13S6xFOZkUVmS02vmqlO+OX38CBaeM4kxRdbiXc69RnOyvHGLgimlMkcqwX05MEVEJoqIHyuAL048SUSmASOApeltojqUnuDuKsvYHapOZp4f8DG+JJftCcHdOe9rl05jdlUxo+3g7nSiVo7I0WGNSmWofoO7MSYM3AY8B2wAnjDGrBORe0TkKtep1wOLjDF9lWzUAOhOEtw7QxFCkSjt3VZ1rCDbx/jSPHY2tON+e5zM3Rna6GTupXl+CrN9WpJRKoOlNM7dGLMEWJKw7+6E7W+lr1kqVU7m3tIZIhiOMrIgQF1rN61dYdq6reCdF/AxvjSX9mCEa3+1lK9ffhKnjRsRy+wLsq1/BqPtmntRThYXTx/NKVVFg3BFSql00OUHMlwwYmXndfaKjZUjcqhr7aalM0Sbnbnn28EdYMWOg/z2ze08vWo3TfZSA4V25j6yIIBHrOD+k4/NPtaXopRKIw3uGc7J3Ovsm1BXleTyzs4mWrpCtNmZeZ7fy7iSvLjnPLJ0R2w7387cs7wezpxcyilVOrlYqUynwT3DOcHdWWvdmXTU0hmmPRgmJ8uLz+thYlkeN8wdx2PLdrJmd3Ps+fkBX2x0DMAfbvnAMWy9Umqg6MJhGc6ZxNTYbpVYnOV269u6aO0KkxewPr+9HuE/PjKTc6aUsbupM/Z8p96ulBpeNLhnOGe0zMGOIADTxxaS5RU27mujrTvcK3iPLMiO29bgrtTwpP+zM5xTlolErSGORTlZTC7PZ9N+azZqXiB+aV7nhhqOvlZ4VEplNs3cM5wT3B15AR/TRhewcV8rbV1h8gOJmXticNfPd6WGIw3uGc6puTvy/FZw393Uyd6Wzl7BXTN3pY4PGtwznDtz9whkZ3mYNqoAgF2NvYO7k7k7Swxo5q7U8KTBPcN1u4J7nt+HiDB9bGFsX3528szdGcuuwV2p4UmDewZZtrWBCXc8GzeU0Z2559pBxd/4AAAcYUlEQVSdp6MLs2MZel5C5j6qMBu/18MpVcVcOXss55ygq3MqNRxp2jbEhSJRnl+3n5auUGzy0V/X7OWWcyYB8cE9z2+9nSLCjLGF1G2spyAhuOcFfDzzhbMZV5LLLVm9b3KtlBoeNHMf4v68ajefe+wd7nxqDVn2TNIt9W2x4+4OVXeWfsLIfADC0d6LdE4dVUC2BnalhjUN7kOcs6wA9Nw+b0tdz02s48oy/p6APW20VXdvbA8OdBOVUkOQlmWGOGeNdoADbVag31TXijEGEYnvUHVl7lfOHsP7e1tYeO6kY9dYpdSQoZn7ENfU0ZN5O1l8U0eIXY1Wp2ow3HO7WndwD/i83HXFdEYWxi83oJQ6PmhwH+LiM/eeQP96jXWD8biau1/r6EopS0rBXUTmichGEakRkTv6OOdjIrJeRNaJyGPpbebxq6kjFBub3tjeTeWIHKpKcnjl/TrAqrk7E5Vy/VplU0pZ+g3uIuIF7gPmA9OB60VkesI5U4A7gQ8aY2YAtw9AW49LzZ0hxtr3No0aq9P0gmkjebOmgfbuMFHTMxEpP6CZu1LKkkrmPgeoMcZsNcYEgUXA1QnnfBq4zxhzEMAYU5feZh6/WjpDjCnquVF1jt/HOVPK6QxFWLnjINAT3HMDmrkrpSypBPcKYJdru9be5zYVmCoib4rIWyIyL9kLichCEVkhIivq6+uPrMXHmabOEKOLejpFc7O8TB1ljWF/f18L0LP4l9bclVKOVIK7JNmXODPGB0wBzgeuBx4UkV434jTG3G+MqTbGVJeXH7/T3pdvb+SRpdv7PS8YjtIRjFCa5yfgs96qXL+XyhG5+L0e3t9rrdnuZO6JSw0opY5fqQT3WqDKtV0J7Elyzl+MMSFjzDZgI1awV0k89U4tP39xc7/nOSNlinKzYoE7x+/F6xHGl+ayYZ8V3LVDVSmVKJXgvhyYIiITRcQPLAAWJ5zzNHABgIiUYZVptqazocNJOGIIJazDnqgzGOH1zVbpqignKzb71Pk+qTwvVpZxbp1XkucfqCYrpTJMv6meMSYsIrcBzwFe4CFjzDoRuQdYYYxZbB+7RETWAxHgX40xDQPZ8EwWiRpCkd5rvrj95PmNPPjGNiAxuFtv2aTyfIzZD8CciSO4aPpIzpgwYgBbrZTKJCn9HW+MWQIsSdh3t+uxAb5sf6l+REz/mft+15oyxbn+WFDPcTL3srzYcb/Pw1mTywagpUqpTKUzVAdBOGoIRw3RqCEcidIRDPc6x+fp6ceOy9zt1RzPnFwaO+736igZpVQ8De6DIGKXZELRKA+9uY15P3u91znu1SDLCwK9MvfKEbmcXGGt/OhJNp5JKXVc0+A+CCLGDu4Rw56mLvY1d/U6p761m0umj2Lz9+aTH/CRZ88+zXGNZX/0k3P5l/Mmcdp4rbUrpeJpcB8EEfsGGuFIlO5wlHC0d/29vq2bkYUBsrw949vd3wFG5Pm5c/5JeuMNpVQvGtwHgXN3pGAkSjAcJWog6rpjUigSpbE9SHm+a2aqU5bJ0rHsSqn+aXAfBE4gD7nGu7tvh9dgL+3rrAYJyTN3pZTqiwb3QeCUYULhaOw2ec6+SNSwuc6aeRof3J1ZqBrclVL907/xB0EklrlHYzfbeHtbI69vPsCYomy+++wGID64J+tQVUqpvmhwHwSRhJo7wM0PLwdgdlXPemvu4F6UkxX3XSmlDkWD+yCIuGruTuY+IjeLgx0hNtmLgU0sy2OkK7jPP3kMZbcEqByRe+wbrJTKOFpzHwRhd1nGztzHFls35OgMRbj29Epe+er5sWGQYC0x8METdIkBpVRqNLgPgkiS4F6a35OlT3CtG6OUUkdCg/sgiCQZChkK90xkmlCqwV0pdXQ0uA+CWHAP94yW6QpHYsfHl2pdXSl1dDS4HwPt3WGaOoKx7WQ1986gFdw9omUZpdTR0+B+DFzw41c55Z4XYtvJhkJ2h6MU52bxyCfnxm6bp5RSR0qD+zFQ51q+F5IPhewMRhhZEODsKToiRil19FIK7iIyT0Q2ikiNiNyR5PjNIlIvIqvtr1vS39ThI1lZpiscwefRz1qlVHr0+/e/iHiB+4CLgVpguYgsNsasTzj1cWPMbQPQxozRFbLq5v0twRu113MPujpUO4MRsrx61w2lVHqkkirOAWqMMVuNMUFgEXD1wDYrM538zef4wPdf6vN42FkB0hkhE4pgx3m6w1F8Xs3clVLpkUo0qQB2ubZr7X2J/klE3hORJ0WkKtkLichCEVkhIivq6+uPoLlDWzhqaOoI9Xm8w87snZp7ezASd9yn98tTSqVJKsE9WcQxCdv/B0wwxswCXgR+l+yFjDH3G2OqjTHV5eXlh9fSYaCj2w7udrre3h1/Y+wszdyVUmmSSjSpBdyZeCWwx32CMabBGOMMCXkAOD09zRte2oNWMI9l7gnB3ac1d6VUmqQS3JcDU0Rkooj4gQXAYvcJIjLGtXkVsCF9TRw+nMzdGS3TlhjcdbSMUipN+h0tY4wJi8htwHOAF3jIGLNORO4BVhhjFgNfEJGrgDDQCNw8gG0e8qJRgydJ/bwjGCYaNbFO1I6EmruOllFKpUtKUyGNMUuAJQn77nY9vhO4M71Ny1ztwTAF2b1vqtERjMTq7ZAkc9eau1IqTTSaDIBHlu7g8eU7e+1vD4Zj9XZI0qGqo2WUUmmii5gMgPteqaGiOIfrzhgXt/+2x1aRndXzeZpYltEOVaVUumjmPgA6ghF2NnYQtbN0v6/n19wV6lm3vfdoGX07lFLpodFkgHSHo9S3WaNDA30EbS3LKKUGigb3NHHX0h07GzsAko6cgSQzVDVzV0qliUaTNHFul+e2o8EK7tEkgT8ZrbkrpdJFg3uaJAvuTuYeivY+lkyWTmJSSqWJRpM0CUXis3OPwM6GdiB5ySYZzdyVUumiwT1NwgmZ+4mjC9nd1GkdSzG468JhSql00WiSJkFXcPf7PIwtzqa9O0LEtdxAf3TJX6VUumhwT5OwqyxTnh8gkOWlKxwh3Ee9XVxx3FlTRkfLKKXSRaNJmrg7VMsKAmT7vHSHonFB3y3b13Mrvhz7tny6cJhSKl00uKeJU5a5avZYbj13EtlZHrrDkVi9/WPVlVx7emXsfGcZAq9HCNjBXZf8VUqli0aTNHEy9KtPGcv8mWMI+Lx0haKxkTIzxhZx/rSRsfOzXdm6U2vX0TJKqXTR4J4mTlnGGfGSneWhKxSJjaLxeSVujZmxxTkAVI8viQV1LcsopdJFV4VME2ecuxOos7O8hKOG7rAd3D3xwf32i6Zw4uhCygsCXPDjV+1z9LNWKZUeGk3SxMnc/a7MHXrum+r1eOIy84DPS3lBAOgZAqmZu1IqXVIK7iIyT0Q2ikiNiNxxiPOuEREjItXpa2JmcIY8OsMZA/ZoGGflxyyvEHBl7l7XmHbnsWbuSql06TeaiIgXuA+YD0wHrheR6UnOKwC+ACxLdyMzQTBslWWyYmUZ61fb2uVk7hI3A9Ud3H1e7VBVSqVXKqniHKDGGLPVGBMEFgFXJznvO8APga40ti9jOJl7T4eqk7lby/om1tzds1GdjF0zd6VUuqQSTSqAXa7tWntfjIicClQZY5451AuJyEIRWSEiK+rr6w+7sUNZ4miZxLKMz+OJ1eMhIXPXoZBKqTRLJbgnizixaZci4gHuBb7S3wsZY+43xlQbY6rLy8tTb2UGcEbLOGWZgF2WabODu9fbf1lGO1SVUumSSnCvBapc25XAHtd2AXAy8KqIbAc+ACw+3jpVe41zT+xQ9Xj67FDVsoxSKt1SiSbLgSkiMlFE/MACYLFz0BjTbIwpM8ZMMMZMAN4CrjLGrBiQFg9R4VjmHj8Usi3Y06HaZ81dO1SVUmnWb3A3xoSB24DngA3AE8aYdSJyj4hcNdANzBQh10xU6OlQbbNHy/gSyjIe6V1z1/XclVLpktIMVWPMEmBJwr67+zj3/KNvVuZxau7+WIeqPYkp1qGakLl7k41z18xdKZUemiqmSSxz9yRk7rGhkJ644B3foWq9DZq5K6XSRaNJmoQiUUR6gnbPOPeemrtIT/buTVKW0Zq7UipdNLinSShiyPJ4EDtox8oywZ7lBwAC3t4jY3S0jFIq3TSapEkoEo0bp95TlunJ3AGynMzdm6xDVTN3pVR6aHBPk3AkGncPVGstGXEtHGYdczpc48oyeg9VpVSa6XruR6mutYuA10swYnp1iGb7vLG1ZZzMPVZzT7b8gI6WUUqliQb3o/Qvj65kUlk+HuldVglkeTjQFgR6l17iR87oaBmlVHppcD9KdS3dZPu8jCoM9ArOzuJh0FNy8dv7PK7gnuWVuJE2Sil1tDRVPEpdoQjNnSFCUdNrKKOzBAG4yjKuG2I7po0uYHZl8cA3Vil13NDM/Sh1BO3gHo7GLekLPSNmoKcM4/d5emXoHz2tko+eVjnwjVVKHTc0cz8Kxhg67cw9nCRzDyRZbiBZcFdKqXTT4H4UukLWkgNt3WE6g5Heo2XiMveeTlMN7kqpgabB/Sh0hiKxxw3t3WQlzDDN9VvB3d1Z6vd6dMijUmrAaXA/Cu7gfqAtSJYvPmiX5QeA+GGPWpZRSh0LGtyPQqe9bgxAY3uw19ow5QVWcBfXnQr9WpZRSh0DOlrmKHQGo3HbY4qy47ad4B6M9Jz3oZNGMbIw/jyllEq3lDJ3EZknIhtFpEZE7khy/FYRWSMiq0XkDRGZnv6mDg0/fX4jL23YD0CHK3MHmFyeH7c90g7ubpfPGsMd808cuAYqpRQpBHcR8QL3AfOB6cD1SYL3Y8aYmcaYU4AfAj9Ne0uHiEfe2sHz66zg7q65A0wqz4vbLk8S3JVS6lhIJXOfA9QYY7YaY4LAIuBq9wnGmBbXZh5g0tfEoaWjOxIrs3QG44N7YuZenq/lF6XU4Eil5l4B7HJt1wJzE08Skc8BXwb8wIXJXkhEFgILAcaNG3e4bR004UgUr0eIRA3BSJRg2A7uCZl75YicuO2yAv8xa6NSSrmlkrknG9rRKzM3xtxnjJkM/BtwV7IXMsbcb4ypNsZUl5eXH15LB9El977GQ29up8MO5rHMPSG4J67HnuvX/mql1OBIJbjXAlWu7UpgzyHOXwR8+GgaNZQYY9jW0M6uxo5YGSaWudvbAZ+H2ZVFg9ZGpZRKlEpquRyYIiITgd3AAuAG9wkiMsUYs9nevBzYzDDRHY5iDISjUTrsYB5KqLmv+dalOutUKTWk9BvcjTFhEbkNeA7wAg8ZY9aJyD3ACmPMYuA2EbkICAEHgZsGstHHkhPAwxETu2Wek7l3hCJkeSV2d6Vkbj5rAvVt3QPfUKWUckmpKGyMWQIsSdh3t+vxF9PcriHDqbOHIiZWY3ePlslxLQ6WzLeumjGwDVRKqSR0+YF+dLpKMR1Jau45/kMHd6WUGgwa3PsRK8tEo7G1ZNyjZXREjFJqKNLg3o9OV1mmvTuhQzUUiVuzXSmlhgoN7v1w1o8JR6I949xdZZlcLcsopYYgDe796HJ3qNqBPhSx5nB1hvrvUFVKqcGgwb0fHYfoUO0IallGKTU0aXDvh1NzD0dNrxmq7d1h8gIa3JVSQ48G9370TGKK0u4aLWOMobE9SGmeLuurlBp6NLj3I5atR0ysLAPQ2h2mrTtMab6u/KiUGno0uPfDGSETjkTj1m/f19wFQHm+Zu5KqaFHg3s/eiYxxWfue5o6ATRzV0oNSRrc++HuRO2MC+5W5l6mmbtSagjS4N6PntEyPR2qAHubNXNXSg1dGtz70eFa8lczd6VUptDg3o+eGarWJKaCbGuhsL3NneQHfDqJSSk1JGlw70eHa8mBzlCEwuwsAPY2d2lJRik1ZGlw70dnyJqNGo5G6QpFKMyxgvuepk4tySilhqyUgruIzBORjSJSIyJ3JDn+ZRFZLyLvichLIjI+/U0dHO7FwrrDUQrtskx3OEppnmbuSqmhqd/gLiJe4D5gPjAduF5EpiectgqoNsbMAp4Efpjuhg4WZ7SMo8Auy4COlFFKDV2pZO5zgBpjzFZjTBBYBFztPsEY84oxpsPefAuoTG8zB4974hIQy9wBinM1uCulhqZUgnsFsMu1XWvv68ungL8mOyAiC0VkhYisqK+vT72Vg6grFMHv6/k1FbiC+4jcrGRPUUqpQZdKcJck+0zSE0VuBKqBHyU7boy53xhTbYypLi8vT72VA8QYw6Nv7aCpI5j0eCgSJRQxsREyEF+WGaGZu1JqiEoluNcCVa7tSmBP4kkichHw78BVxpju9DRvYNUe7OQbT6/lb2v3JT3u1NvdpZjCHHfmrsFdKTU0pRLclwNTRGSiiPiBBcBi9wkicirwa6zAXpf+Zg4MZzmBtu5w0uPOjNSCnD4y9zwtyyilhqZ+g7sxJgzcBjwHbACeMMasE5F7ROQq+7QfAfnAn0RktYgs7uPlhhQneCd2miYej8vcXcFdO1SVUkOVr/9TwBizBFiSsO9u1+OL0tyuY6K/4O7sL4zL3LUso5Qa+o7rGapOTb0z2EdZJknN3R3ci3K0LKOUGpqO6+DuZObt/ZZleoJ4fqAnuHs9yQYSKaXU4Duug3tP5t5HcA/1LsvoKpBKqUxwfAf3WOaevCzjrAjpLssEso7rX5lSKkMc15HKycz76lB11nJ3D38M+DRzV0oNfcd1cO+IjZbpK3N3yjI9mXu2nblnawavlBrCUhoKOVw5o2Q6ghGMMfz3q1u4ePoopo4qsI6H4jtURcDv9fDCl87VMe5KqSHtuE4/Y2WZ7gi1Bzv50XMbueTe16g9aC1w2RmMIAJ59giZbJ8XEWHKqALKC/RGHUqpoeu4Du7usszWA+2x/X9ZbS2d0xmMkJvlJctrDXnUzlSlVKY4rqOV02HaGYqwrb4ttv9Am7XuWUcoQo7fS5bXrrNrZ6pSKkMc1zV3J3MPRQwb97eRH/BRkuenoc1aArgraAV3n1c7UZVSmeW4Du7uyUvr9zQzsSwPn1dobLeCe0cwQk6Wlyx7JqpOYFJKZYrjOhV13x917Z4WJpblUZoXiJVlOkMRcvy+WOYe8B3Xvy6lVAY5rqOVO3OPRI0d3P2xzL0zGCEny+PqUNXMXSmVGY7r4N4RjMQtLTB1VAGl+VZwN8bQGYqQ6/f1dKhqcFdKZYhhUXPvDkdYvu0g1RNG8Ne1ewmFe9/idXdTJ39bu4+Lp4/i9oumsGxbI61dIcryA7R0WZOZZlUWsbe5k3DU8MrGOva3dDGuNBefU3PXsoxSKkMMi+D+6NIdfPfZDZw3tZy/b6rv87wTRxfwy1dqCEWi/Pq1rQBMG10QG+NeOSKHsnxrctInf7sCgJwsb2xpXy3LKKUyRUrBXUTmAT8HvMCDxpgfJBw/F/gZMAtYYIx5Mt0NPRTnBtd/31TPWZNL+dG1s3ud4/d6KMnzM/vbz/P7t3bE9pfm9cw0FRFK8uKXFcjyehAR/F6PZu5KqYzRb3AXES9wH3AxUAssF5HFxpj1rtN2AjcDXx2IRro1tHVzwB6HDtDWHWLlzoOMLcpmT3MXnzl/MhXFOX0+f3ZVEW/WNMS2i3OtdWPGFGUDUJofH9xX7mgEwOcVrbkrpTJGKpn7HKDGGLMVQEQWAVcDseBujNluH4sOQBvjPLmylu//9f1e+x+4qZrWrjAfmFR6yOefPm5EXHAfWRDgY9WVLDx3EhCfyRcEfNx63mQArjm9knOnlKfjEpRSasClEtwrgF2u7Vpg7pH8MBFZCCwEGDdu3JG8BBdNH0VVSW7cvpI8PzPGFqX0/FPHjwBgdmUR79Y209gR5IfX9JRxnMx94bmT+PplJ8X233P1yUfUXqWUGgypBPdkNwrtPRwlBcaY+4H7Aaqrq4/oNSaX5zO5PP9IngrAmZNK+fQ5E/nk2RN5ZOkOPnHWhLjjWV4P739nnk5YUkpltFSCey1Q5dquBPYMTHMGXnaWl3+/fDoA/zbvxD7PUUqpTJZKerocmCIiE0XEDywAFg9ss5RSSh2NfoO7MSYM3AY8B2wAnjDGrBORe0TkKgAROUNEaoFrgV+LyLqBbLRSSqlDS2mcuzFmCbAkYd/drsfLsco1SimlhgDtNVRKqWFIg7tSSg1DGtyVUmoY0uCulFLDkAZ3pZQahsSYI5ooevQ/WKQe2NHvib2VAQfS3JzBotcyNOm1DE16LZbxxph+F7oatOB+pERkhTGmerDbkQ56LUOTXsvQpNdyeLQso5RSw5AGd6WUGoYyMbjfP9gNSCO9lqFJr2Vo0ms5DBlXc1dKKdW/TMzclVJK9UODu1JKDUMZFdxFZJ6IbBSRGhG5Y7Dbc7hEZLuIrBGR1SKywt5XIiIviMhm+/uIwW5nMiLykIjUicha176kbRfLL+z36T0ROW3wWt5bH9fyLRHZbb83q0XkMtexO+1r2Sgilw5Oq3sTkSoReUVENojIOhH5or0/496XQ1xLJr4v2SLytoi8a1/Lt+39E0Vkmf2+PG7fHwMRCdjbNfbxCWlpiDEmI74AL7AFmAT4gXeB6YPdrsO8hu1AWcK+HwJ32I/vAP5zsNvZR9vPBU4D1vbXduAy4K9Yt2j8ALBssNufwrV8C/hqknOn2//WAsBE+9+gd7CvwW7bGOA0+3EBsMlub8a9L4e4lkx8XwTItx9nAcvs3/cTwAJ7/6+Az9iPPwv8yn68AHg8He3IpMx9DlBjjNlqjAkCi4CrB7lN6XA18Dv78e+ADw9iW/pkjHkNaEzY3VfbrwYeMZa3gGIRGXNsWtq/Pq6lL1cDi4wx3caYbUAN1r/FQWeM2WuMecd+3Ip1M50KMvB9OcS19GUovy/GGNNmb2bZXwa4EHjS3p/4vjjv15PAh0Qk2b2rD0smBfcKYJdru5ZDv/lDkQGeF5GVIrLQ3jfKGLMXrH/gwMhBa93h66vtmfpe3WaXKx5ylccy4lrsP+VPxcoSM/p9SbgWyMD3RUS8IrIaqANewPrLoslYd7aD+PbGrsU+3gyUHm0bMim4J/sky7RxnB80xpwGzAc+JyLnDnaDBkgmvlf/A0wGTgH2Aj+x9w/5axGRfOB/gduNMS2HOjXJvqF+LRn5vhhjIsaYU7DuUDcHOCnZafb3AbmWTArutUCVa7sS2DNIbTkixpg99vc64M9Yb/p+509j+3vd4LXwsPXV9ox7r4wx++3/kFHgAXr+xB/S1yIiWVjB8A/GmKfs3Rn5viS7lkx9XxzGmCbgVayae7GIOLc2dbc3di328SJSLxv2KZOC+3Jgit3j7MfqeFg8yG1KmYjkiUiB8xi4BFiLdQ032afdBPxlcFp4RPpq+2Lg4/bojA8AzU6ZYKhKqD1/BOu9AetaFtgjGiYCU4C3j3X7krHrsr8BNhhjfuo6lHHvS1/XkqHvS7mIFNuPc4CLsPoQXgGusU9LfF+c9+sa4GVj964elcHuWT7MXujLsHrRtwD/PtjtOcy2T8Lq3X8XWOe0H6u29hKw2f5eMtht7aP9f8T6sziElWl8qq+2Y/2ZeZ/9Pq0Bqge7/Slcy6N2W9+z/7ONcZ3/7/a1bATmD3b7Xe06G+vP9/eA1fbXZZn4vhziWjLxfZkFrLLbvBa4294/CesDqAb4ExCw92fb2zX28UnpaIcuP6CUUsNQJpVllFJKpUiDu1JKDUMa3JVSahjS4K6UUsOQBnellBqGNLgrpdQwpMFdKaWGof8P1znc5vmdUMIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(1, niter + 1), loss2)\n",
    "plt.title('training loss')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, niter + 1), accuracy_test)\n",
    "plt.title('validation accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
